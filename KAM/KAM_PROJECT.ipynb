{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//----------------------------\n",
    "#//LIBRARIES\n",
    "    #Math\n",
    "import math\n",
    "    #Numeric Python\n",
    "import numpy as np\n",
    "    #Pandas (dataframes)\n",
    "import pandas as pd\n",
    "    #datetime for fate manipulation\n",
    "from datetime import date, datetime, timedelta  \n",
    "    #Regex for advanced string matching\n",
    "import re\n",
    "    #for time related stuff\n",
    "import time\n",
    "    #json library\n",
    "import json\n",
    "    #Analyst tools\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from analysts_tools.growth import *\n",
    "    #Procurement tools\n",
    "from procurement_lib import send_slack_notification\n",
    "from procurement_lib import redash\n",
    "from analystcommunity.read_connection_data_warehouse import run_read_dwd_query\n",
    "from analysts_tools.redash_methods import *\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargue de Queries y parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'BAQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "df_kams_ctm = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",169591,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)\n",
    "df_kams_ctm[[\"customer_id\"]] = df_kams_ctm[[\"customer_id\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "df_bench = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",175456,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "frida_products = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",118629,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer_segments = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",178794,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "split_part(bs.upc, '-',1) as region_code\n",
    "--,bs.sku_id\n",
    "--,split_part(bs.upc, ':',4) as IdProd\n",
    ",bs.addl_product_id as card_id\n",
    "--,bs.upc\n",
    ",bcat2.name as categoria\n",
    ",bcat.name as subcategoria\n",
    ",        CASE\n",
    "            WHEN ((bs.active_end_date IS NULL OR bs.active_end_date > CURRENT_TIMESTAMP) AND (bs2.active_end_date IS NULL OR bs2.active_end_date > CURRENT_TIMESTAMP)) THEN 'on'\n",
    "            ELSE 'off'\n",
    "        END as status_frida\n",
    "\n",
    "\n",
    "from postgres_broadleaf_federate.\"broadleaf.blc_sku\" bs\n",
    "LEFT join postgres_broadleaf_federate.\"broadleaf.blc_product\" bp  on bp.product_id = bs.addl_product_id --Conectar sku con la tarjeta\n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_sku\" bs2 on bs2.sku_id = bp.default_sku_id --Conectar la tarjeta con el sku que guarda la info\n",
    "left join postgres_broadleaf_federate.\"broadleaf.blc_category_xref\" bcx on bcx.sub_category_id = bp.default_category_id and bcx.archived='N' and bcx.sndbx_tier is null and default_reference = 'true' --Relaciones categorias \n",
    "left join postgres_broadleaf_federate.\"broadleaf.blc_category\" bcat on bp.default_category_id = bcat.category_id --Nombre subcategoria\n",
    "left join postgres_broadleaf_federate.\"broadleaf.blc_category\" bcat2 on bcx.category_id = bcat2.category_id --Nombre categoria\n",
    "\n",
    "where \n",
    "bs.archived = 'N'\n",
    "and bs.sndbx_id is null\n",
    "and bp.archived = 'N'\n",
    "and bs.catalog_disc < 0\n",
    "and ((bp.archived = 'N' and bp.sndbx_id is null) or (bp.archived is null))\n",
    "\"\"\"\n",
    "df_skus = read_connection_data_warehouse.runQuery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH MaxSubmissionDates AS (\n",
    "    SELECT\n",
    "        su.card_id,\n",
    "        MAX(submit_date.full_date) AS max_submission_date\n",
    "    FROM dpr_sales.fact_sales s\n",
    "    LEFT JOIN dpr_shared.dim_date submit_date\n",
    "        ON s.dim_submitted_date = submit_date.date_id\n",
    "    LEFT JOIN dpr_shared.dim_stock_unit su\n",
    "        ON s.dim_product = su.product_id\n",
    "    WHERE submit_date.full_date >= DATE(GETDATE()) - 10\n",
    "        AND s.dim_status = 1\n",
    "    GROUP BY su.card_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    s.dim_submitted_date,\n",
    "    su.card_id,\n",
    "    CASE WHEN su.source_parent_id = 0 THEN su.source_id ELSE su.source_parent_id END AS parent_id,\n",
    "    SUM((s.product_price * s.product_quantity_x_step_unit)) / NULLIF(SUM(s.product_quantity_x_step_unit), 0) AS gross_price_no_iva,\n",
    "    SUM((s.product_price * s.product_quantity_x_step_unit) + s.product_tax_iva) / NULLIF(SUM(s.product_quantity_x_step_unit), 0) AS gross_price\n",
    "FROM dpr_sales.fact_sales s\n",
    "LEFT JOIN dpr_shared.dim_site site\n",
    "    ON s.dim_site = site.site_id\n",
    "LEFT JOIN dpr_shared.dim_date submit_date\n",
    "    ON s.dim_submitted_date = submit_date.date_id\n",
    "LEFT JOIN dpr_shared.dim_stock_unit su\n",
    "    ON s.dim_product = su.product_id\n",
    "INNER JOIN MaxSubmissionDates msd\n",
    "    ON su.card_id = msd.card_id\n",
    "    AND submit_date.full_date = msd.max_submission_date\n",
    "GROUP BY 1, 2, 3\n",
    "\"\"\"\n",
    "df_prices = run_read_dwd_query(query)\n",
    "df_prices[[\"gross_price_no_iva\",\"gross_price\"]] = df_prices[[\"gross_price_no_iva\",\"gross_price\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = pd.merge(df_prices, df_bench[['extracted_id','benchmark']],  how='left', left_on=['parent_id'], right_on = ['extracted_id'])\n",
    "df_prices.drop(columns=['extracted_id'], inplace=True)\n",
    "\n",
    "df_prices = df_prices.groupby(['card_id']).agg({'gross_price_no_iva':np.mean,'gross_price':np.mean,'benchmark':np.mean}).reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH base_skus AS (\n",
    "    SELECT DISTINCT\n",
    "        bo.offer_id,\n",
    "        bo.offer_value/100.00 AS dct,\n",
    "        bocsx.customer_segment_id,\n",
    "        REPLACE(SPLIT_PART(SPLIT_PART(boic.order_item_match_rule, '[',2),']',1),'\"','') AS skus\n",
    "            \n",
    "    FROM postgres_broadleaf_federate.\"broadleaf.blc_offer\"                          bo\n",
    "    LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_offer_customer_seg_xref\"   bocsx   ON (bo.offer_id = bocsx.offer_id AND ((bocsx.archived is NULL OR bocsx.archived='N')))\n",
    "    LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_customer_offer_xref\"       bcox    ON (bo.offer_id = bcox.offer_id  )\n",
    "    LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_tar_crit_offer_xref\"       btcofx  ON (btcofx.offer_id = bo.offer_id)\n",
    "    INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_offer_item_criteria\"      boic    ON (btcofx.offer_item_criteria_id = boic.offer_item_criteria_id AND (boic.archived is NULL OR boic.archived ='N'))\n",
    "    INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_site\"                     bs      ON bs.site_id = bo.catalog_disc\n",
    "\n",
    "    WHERE   \n",
    "        (bo.end_date >= CURRENT_dATE or bo.end_date IS NULL)\n",
    "        AND bo.start_date <= CURRENT_DATE\n",
    "        ---TIME VALIDATIONS\n",
    "        -------------------\n",
    "        AND bo.offer_discount_type = 'PERCENT_OFF'\n",
    "        AND bo.offer_type = 'ORDER_ITEM'\n",
    "        AND bo.sndbx_id is NULL\n",
    "        AND (bo.archived is NULL OR bo.archived='N')\n",
    "        AND (bo.sndbx_tier is NULL OR bo.sndbx_tier = 999999)\n",
    "        AND bo.automatically_added = 'true'\n",
    "        AND (boic.sndbx_tier is NULL OR bo.sndbx_tier = 999999)\n",
    "        AND (bocsx.sndbx_tier is NULL OR bocsx.sndbx_tier = 999999)\n",
    "        --AND bocsx.customer_segment_id IS NOT NULL\n",
    "        AND bs.site_identifier_value = 'BOG'\n",
    "        AND (bo.max_uses_per_customer <> 1 OR bo.max_uses_per_customer IS NULL)\n",
    "    ),\n",
    "    \n",
    "    tab_unnest AS (\n",
    "        SELECT 1 AS n UNION ALL\n",
    "        SELECT 2 AS n UNION ALL\n",
    "        SELECT 3 AS n UNION ALL\n",
    "        SELECT 4 AS n UNION ALL\n",
    "        SELECT 5 AS n UNION ALL\n",
    "        SELECT 6 AS n UNION ALL\n",
    "        SELECT 7 AS n UNION ALL\n",
    "        SELECT 8 AS n UNION ALL\n",
    "        SELECT 9 AS n UNION ALL\n",
    "        SELECT 10 AS n UNION ALL\n",
    "        SELECT 11 AS n UNION ALL\n",
    "        SELECT 12 AS n UNION ALL\n",
    "        SELECT 13 AS n UNION ALL\n",
    "        SELECT 14 AS n UNION ALL\n",
    "        SELECT 15 AS n UNION ALL\n",
    "        SELECT 16 AS n UNION ALL\n",
    "        SELECT 17 AS n UNION ALL\n",
    "        SELECT 18 AS n UNION ALL\n",
    "        SELECT 19 AS n UNION ALL\n",
    "        SELECT 20 AS n UNION ALL\n",
    "        SELECT 21 AS n UNION ALL\n",
    "        SELECT 22 AS n UNION ALL\n",
    "        SELECT 23 AS n UNION ALL\n",
    "        SELECT 24 AS n UNION ALL\n",
    "        SELECT 25 AS n UNION ALL\n",
    "        SELECT 26 AS n UNION ALL\n",
    "        SELECT 27 AS n UNION ALL\n",
    "        SELECT 28 AS n UNION ALL\n",
    "        SELECT 29 AS n UNION ALL\n",
    "        SELECT 30 AS n UNION ALL\n",
    "        SELECT 31 AS n UNION ALL\n",
    "        SELECT 32 AS n UNION ALL\n",
    "        SELECT 33 AS n UNION ALL\n",
    "        SELECT 34 AS n UNION ALL\n",
    "        SELECT 35 AS n UNION ALL\n",
    "        SELECT 36 AS n UNION ALL\n",
    "        SELECT 37 AS n UNION ALL\n",
    "        SELECT 38 AS n UNION ALL\n",
    "        SELECT 39 AS n UNION ALL\n",
    "        SELECT 40 AS n UNION ALL\n",
    "        SELECT 41 AS n UNION ALL\n",
    "        SELECT 42 AS n UNION ALL\n",
    "        SELECT 43 AS n UNION ALL\n",
    "        SELECT 44 AS n UNION ALL\n",
    "        SELECT 45 AS n UNION ALL\n",
    "        SELECT 46 AS n UNION ALL\n",
    "        SELECT 47 AS n UNION ALL\n",
    "        SELECT 48 AS n UNION ALL\n",
    "        SELECT 49 AS n UNION ALL\n",
    "        SELECT 50 AS n UNION ALL\n",
    "        SELECT 51 AS n UNION ALL\n",
    "        SELECT 52 AS n UNION ALL\n",
    "        SELECT 53 AS n UNION ALL\n",
    "        SELECT 54 AS n UNION ALL\n",
    "        SELECT 55 AS n UNION ALL\n",
    "        SELECT 56 AS n UNION ALL\n",
    "        SELECT 57 AS n UNION ALL\n",
    "        SELECT 58 AS n UNION ALL\n",
    "        SELECT 59 AS n UNION ALL\n",
    "        SELECT 60 AS n UNION ALL\n",
    "        SELECT 61 AS n UNION ALL\n",
    "        SELECT 62 AS n UNION ALL\n",
    "        SELECT 63 AS n UNION ALL\n",
    "        SELECT 64 AS n UNION ALL\n",
    "        SELECT 65 AS n UNION ALL\n",
    "        SELECT 66 AS n UNION ALL\n",
    "        SELECT 67 AS n UNION ALL\n",
    "        SELECT 68 AS n UNION ALL\n",
    "        SELECT 69 AS n UNION ALL\n",
    "        SELECT 70 AS n UNION ALL\n",
    "        SELECT 71 AS n UNION ALL\n",
    "        SELECT 72 AS n UNION ALL\n",
    "        SELECT 73 AS n UNION ALL\n",
    "        SELECT 74 AS n UNION ALL\n",
    "        SELECT 75 AS n UNION ALL\n",
    "        SELECT 76 AS n UNION ALL\n",
    "        SELECT 77 AS n UNION ALL\n",
    "        SELECT 78 AS n UNION ALL\n",
    "        SELECT 79 AS n UNION ALL\n",
    "        SELECT 80 AS n UNION ALL\n",
    "        SELECT 81 AS n UNION ALL\n",
    "        SELECT 82 AS n UNION ALL\n",
    "        SELECT 83 AS n UNION ALL\n",
    "        SELECT 84 AS n UNION ALL\n",
    "        SELECT 85 AS n UNION ALL\n",
    "        SELECT 86 AS n UNION ALL\n",
    "        SELECT 87 AS n UNION ALL\n",
    "        SELECT 88 AS n UNION ALL\n",
    "        SELECT 89 AS n UNION ALL\n",
    "        SELECT 90 AS n UNION ALL\n",
    "        SELECT 91 AS n UNION ALL\n",
    "        SELECT 92 AS n UNION ALL\n",
    "        SELECT 93 AS n UNION ALL\n",
    "        SELECT 94 AS n UNION ALL\n",
    "        SELECT 95 AS n UNION ALL\n",
    "        SELECT 96 AS n UNION ALL\n",
    "        SELECT 97 AS n UNION ALL\n",
    "        SELECT 98 AS n UNION ALL\n",
    "        SELECT 99 AS n UNION ALL\n",
    "        SELECT 100 AS n UNION ALL\n",
    "        SELECT 101 AS n UNION ALL\n",
    "        SELECT 102 AS n UNION ALL\n",
    "        SELECT 103 AS n UNION ALL\n",
    "        SELECT 104 AS n UNION ALL\n",
    "        SELECT 105 AS n UNION ALL\n",
    "        SELECT 106 AS n UNION ALL\n",
    "        SELECT 107 AS n UNION ALL\n",
    "        SELECT 108 AS n UNION ALL\n",
    "        SELECT 109 AS n UNION ALL\n",
    "        SELECT 110 AS n UNION ALL\n",
    "        SELECT 111 AS n UNION ALL\n",
    "        SELECT 112 AS n UNION ALL\n",
    "        SELECT 113 AS n UNION ALL\n",
    "        SELECT 114 AS n UNION ALL\n",
    "        SELECT 115 AS n UNION ALL\n",
    "        SELECT 116 AS n UNION ALL\n",
    "        SELECT 117 AS n UNION ALL\n",
    "        SELECT 118 AS n UNION ALL\n",
    "        SELECT 119 AS n UNION ALL\n",
    "        SELECT 120 AS n\n",
    "    ),\n",
    "     \n",
    "    info_skus AS (  \n",
    "    SELECT \n",
    "        bs.offer_id,\n",
    "        bs.dct,\n",
    "        bs.customer_segment_id,\n",
    "        TRIM(SPLIT_PART(bs.skus, ',', tab_unnest.n)) AS sku\n",
    "        \n",
    "    FROM tab_unnest\n",
    "    INNER JOIN base_skus bs ON tab_unnest.n <= REGEXP_COUNT(bs.skus, ',') + 1\n",
    "    )\n",
    "    \n",
    "SELECT DISTINCT\n",
    "    s.site_identifier_value as ciudad,\n",
    "    bcs.external_identifier::int AS customer_id,\n",
    "    bs.addl_product_id AS card_id,\n",
    "    MAX(bo.dct) AS dct\n",
    "    \n",
    "FROM info_skus bo\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_sku\"                          bs      ON bs.sku_id = bo.sku\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_customer_customer_seg_xref\"   bcs     ON bo.customer_segment_id = bcs.customer_segment_id AND bo.customer_segment_id IS NOT NULL AND bcs.external_identifier ~ '^[0-9]+$'\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_site\"                         s       ON s.site_id = bs.catalog_disc\n",
    "\n",
    "GROUP BY 1,2,3\n",
    "\"\"\"\n",
    "df_filt_offers = read_connection_data_warehouse.runQuery(query)\n",
    "df_filt_offers[[\"dct\"]] = df_filt_offers[[\"dct\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH base_skus AS (\n",
    "    SELECT DISTINCT\n",
    "        bo.offer_id,\n",
    "        bo.offer_value/100.00 AS dct,\n",
    "        bocsx.customer_segment_id,\n",
    "        REPLACE(SPLIT_PART(SPLIT_PART(boic.order_item_match_rule, '[',2),']',1),'\"','') AS skus\n",
    "            \n",
    "    FROM postgres_broadleaf_federate.\"broadleaf.blc_offer\"                          bo\n",
    "    LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_offer_customer_seg_xref\"   bocsx   ON (bo.offer_id = bocsx.offer_id AND ((bocsx.archived is NULL OR bocsx.archived='N')))\n",
    "    LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_customer_offer_xref\"       bcox    ON (bo.offer_id = bcox.offer_id  )\n",
    "    LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_tar_crit_offer_xref\"       btcofx  ON (btcofx.offer_id = bo.offer_id)\n",
    "    INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_offer_item_criteria\"      boic    ON (btcofx.offer_item_criteria_id = boic.offer_item_criteria_id AND (boic.archived is NULL OR boic.archived ='N'))\n",
    "    INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_site\"                     bs      ON bs.site_id = bo.catalog_disc\n",
    "\n",
    "    WHERE   \n",
    "        (bo.end_date >= CURRENT_dATE or bo.end_date IS NULL)\n",
    "        AND bo.start_date <= CURRENT_DATE\n",
    "        ---TIME VALIDATIONS\n",
    "        -------------------\n",
    "        AND bo.offer_discount_type = 'PERCENT_OFF'\n",
    "        AND bo.offer_type = 'ORDER_ITEM'\n",
    "        AND bo.sndbx_id is NULL\n",
    "        AND (bo.archived is NULL OR bo.archived='N')\n",
    "        AND (bo.sndbx_tier is NULL OR bo.sndbx_tier = 999999)\n",
    "        AND bo.automatically_added = 'true'\n",
    "        AND (boic.sndbx_tier is NULL OR bo.sndbx_tier = 999999)\n",
    "        AND (bocsx.sndbx_tier is NULL OR bocsx.sndbx_tier = 999999)\n",
    "        --AND bocsx.customer_segment_id IS NOT NULL\n",
    "        AND bs.site_identifier_value = 'BOG'\n",
    "        AND (bo.max_uses_per_customer <> 1 OR bo.max_uses_per_customer IS NULL)\n",
    "    ),\n",
    "    \n",
    "    tab_unnest AS (\n",
    "        SELECT 1 AS n UNION ALL\n",
    "        SELECT 2 AS n UNION ALL\n",
    "        SELECT 3 AS n UNION ALL\n",
    "        SELECT 4 AS n UNION ALL\n",
    "        SELECT 5 AS n UNION ALL\n",
    "        SELECT 6 AS n UNION ALL\n",
    "        SELECT 7 AS n UNION ALL\n",
    "        SELECT 8 AS n UNION ALL\n",
    "        SELECT 9 AS n UNION ALL\n",
    "        SELECT 10 AS n UNION ALL\n",
    "        SELECT 11 AS n UNION ALL\n",
    "        SELECT 12 AS n UNION ALL\n",
    "        SELECT 13 AS n UNION ALL\n",
    "        SELECT 14 AS n UNION ALL\n",
    "        SELECT 15 AS n UNION ALL\n",
    "        SELECT 16 AS n UNION ALL\n",
    "        SELECT 17 AS n UNION ALL\n",
    "        SELECT 18 AS n UNION ALL\n",
    "        SELECT 19 AS n UNION ALL\n",
    "        SELECT 20 AS n UNION ALL\n",
    "        SELECT 21 AS n UNION ALL\n",
    "        SELECT 22 AS n UNION ALL\n",
    "        SELECT 23 AS n UNION ALL\n",
    "        SELECT 24 AS n UNION ALL\n",
    "        SELECT 25 AS n UNION ALL\n",
    "        SELECT 26 AS n UNION ALL\n",
    "        SELECT 27 AS n UNION ALL\n",
    "        SELECT 28 AS n UNION ALL\n",
    "        SELECT 29 AS n UNION ALL\n",
    "        SELECT 30 AS n UNION ALL\n",
    "        SELECT 31 AS n UNION ALL\n",
    "        SELECT 32 AS n UNION ALL\n",
    "        SELECT 33 AS n UNION ALL\n",
    "        SELECT 34 AS n UNION ALL\n",
    "        SELECT 35 AS n UNION ALL\n",
    "        SELECT 36 AS n UNION ALL\n",
    "        SELECT 37 AS n UNION ALL\n",
    "        SELECT 38 AS n UNION ALL\n",
    "        SELECT 39 AS n UNION ALL\n",
    "        SELECT 40 AS n UNION ALL\n",
    "        SELECT 41 AS n UNION ALL\n",
    "        SELECT 42 AS n UNION ALL\n",
    "        SELECT 43 AS n UNION ALL\n",
    "        SELECT 44 AS n UNION ALL\n",
    "        SELECT 45 AS n UNION ALL\n",
    "        SELECT 46 AS n UNION ALL\n",
    "        SELECT 47 AS n UNION ALL\n",
    "        SELECT 48 AS n UNION ALL\n",
    "        SELECT 49 AS n UNION ALL\n",
    "        SELECT 50 AS n UNION ALL\n",
    "        SELECT 51 AS n UNION ALL\n",
    "        SELECT 52 AS n UNION ALL\n",
    "        SELECT 53 AS n UNION ALL\n",
    "        SELECT 54 AS n UNION ALL\n",
    "        SELECT 55 AS n UNION ALL\n",
    "        SELECT 56 AS n UNION ALL\n",
    "        SELECT 57 AS n UNION ALL\n",
    "        SELECT 58 AS n UNION ALL\n",
    "        SELECT 59 AS n UNION ALL\n",
    "        SELECT 60 AS n UNION ALL\n",
    "        SELECT 61 AS n UNION ALL\n",
    "        SELECT 62 AS n UNION ALL\n",
    "        SELECT 63 AS n UNION ALL\n",
    "        SELECT 64 AS n UNION ALL\n",
    "        SELECT 65 AS n UNION ALL\n",
    "        SELECT 66 AS n UNION ALL\n",
    "        SELECT 67 AS n UNION ALL\n",
    "        SELECT 68 AS n UNION ALL\n",
    "        SELECT 69 AS n UNION ALL\n",
    "        SELECT 70 AS n UNION ALL\n",
    "        SELECT 71 AS n UNION ALL\n",
    "        SELECT 72 AS n UNION ALL\n",
    "        SELECT 73 AS n UNION ALL\n",
    "        SELECT 74 AS n UNION ALL\n",
    "        SELECT 75 AS n UNION ALL\n",
    "        SELECT 76 AS n UNION ALL\n",
    "        SELECT 77 AS n UNION ALL\n",
    "        SELECT 78 AS n UNION ALL\n",
    "        SELECT 79 AS n UNION ALL\n",
    "        SELECT 80 AS n UNION ALL\n",
    "        SELECT 81 AS n UNION ALL\n",
    "        SELECT 82 AS n UNION ALL\n",
    "        SELECT 83 AS n UNION ALL\n",
    "        SELECT 84 AS n UNION ALL\n",
    "        SELECT 85 AS n UNION ALL\n",
    "        SELECT 86 AS n UNION ALL\n",
    "        SELECT 87 AS n UNION ALL\n",
    "        SELECT 88 AS n UNION ALL\n",
    "        SELECT 89 AS n UNION ALL\n",
    "        SELECT 90 AS n UNION ALL\n",
    "        SELECT 91 AS n UNION ALL\n",
    "        SELECT 92 AS n UNION ALL\n",
    "        SELECT 93 AS n UNION ALL\n",
    "        SELECT 94 AS n UNION ALL\n",
    "        SELECT 95 AS n UNION ALL\n",
    "        SELECT 96 AS n UNION ALL\n",
    "        SELECT 97 AS n UNION ALL\n",
    "        SELECT 98 AS n UNION ALL\n",
    "        SELECT 99 AS n UNION ALL\n",
    "        SELECT 100 AS n UNION ALL\n",
    "        SELECT 101 AS n UNION ALL\n",
    "        SELECT 102 AS n UNION ALL\n",
    "        SELECT 103 AS n UNION ALL\n",
    "        SELECT 104 AS n UNION ALL\n",
    "        SELECT 105 AS n UNION ALL\n",
    "        SELECT 106 AS n UNION ALL\n",
    "        SELECT 107 AS n UNION ALL\n",
    "        SELECT 108 AS n UNION ALL\n",
    "        SELECT 109 AS n UNION ALL\n",
    "        SELECT 110 AS n UNION ALL\n",
    "        SELECT 111 AS n UNION ALL\n",
    "        SELECT 112 AS n UNION ALL\n",
    "        SELECT 113 AS n UNION ALL\n",
    "        SELECT 114 AS n UNION ALL\n",
    "        SELECT 115 AS n UNION ALL\n",
    "        SELECT 116 AS n UNION ALL\n",
    "        SELECT 117 AS n UNION ALL\n",
    "        SELECT 118 AS n UNION ALL\n",
    "        SELECT 119 AS n UNION ALL\n",
    "        SELECT 120 AS n\n",
    "    ),\n",
    "     \n",
    "    info_skus AS (  \n",
    "    SELECT \n",
    "        bs.offer_id,\n",
    "        bs.dct,\n",
    "        bs.customer_segment_id,\n",
    "        TRIM(SPLIT_PART(bs.skus, ',', tab_unnest.n)) AS sku\n",
    "        \n",
    "    FROM tab_unnest\n",
    "    INNER JOIN base_skus bs ON tab_unnest.n <= REGEXP_COUNT(bs.skus, ',') + 1\n",
    "    )\n",
    "    \n",
    "SELECT DISTINCT\n",
    "    s.site_identifier_value as ciudad,\n",
    "    --bcs.external_identifier::int AS customer_id,\n",
    "    bs.addl_product_id AS card_id,\n",
    "    MAX(bo.dct) AS dct\n",
    "    \n",
    "FROM info_skus bo\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_sku\"                          bs      ON bs.sku_id = bo.sku\n",
    "--INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_customer_customer_seg_xref\"   bcs     ON bo.customer_segment_id = bcs.customer_segment_id AND bo.customer_segment_id IS NOT NULL AND bcs.external_identifier ~ '^[0-9]+$'\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_site\"                         s       ON s.site_id = bs.catalog_disc\n",
    "\n",
    "WHERE bo.customer_segment_id IS NULL\n",
    "GROUP BY 1,2--,3\n",
    "\"\"\"\n",
    "df_no_filt_offers = read_connection_data_warehouse.runQuery(query)\n",
    "df_no_filt_offers[[\"dct\"]] = df_no_filt_offers[[\"dct\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT \n",
    "region,\n",
    "sku,\n",
    "CAST(day AS date) AS day,\n",
    "MAX(CASE WHEN account = 'GMV Resale Subtotal Acumulado' THEN value END) AS gmv_value,\n",
    "MAX(CASE WHEN account = 'COGS Acumulado' THEN value END) AS cogs_value,\n",
    "(MAX(CASE WHEN account = 'GMV Resale Subtotal Acumulado' THEN value END) - MAX(CASE WHEN account = 'COGS Acumulado' THEN value END)) / MAX(CASE WHEN account = 'GMV Resale Subtotal Acumulado' THEN value END) AS margin\n",
    "\n",
    "FROM mvp_operations.raw_data_aleph\n",
    "\n",
    "WHERE (CAST(day AS date) = DATEADD(day, -1, DATEADD(month, 1, DATE_TRUNC('month', CAST(day AS date)))) OR CAST(day AS date) = DATEADD(day, -1, CURRENT_DATE) OR CAST(day AS date) = '2022-12-14' OR CAST(day AS date) = '2023-03-18')\n",
    "AND CAST(day AS date) > DATE_TRUNC('month', date(getdate()) - interval '0 month')\n",
    "AND value > 1\n",
    "\n",
    "GROUP BY 1,2,3\n",
    "\"\"\"\n",
    "df_margen = run_read_dwd_query(query)\n",
    "df_margen[[\"margin\"]] = df_margen[[\"margin\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT \n",
    "  p.region_code,\n",
    "  p.name AS sku_name,\n",
    "  bs2.name AS card_name,\n",
    "  bs.addl_product_id AS card_id,\n",
    "  p.product_id AS product_id,\n",
    "  bs.sku_id,\n",
    "  p.sku,\n",
    "  bcat2.name as cat,\n",
    "  bcat.name as subcat\n",
    "FROM postgres_main_co.\"purchase_orders.products\"                        p\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_sku\"              bs      ON bs.upc = p.sku\n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_product\"           bp      ON bp.product_id = bs.addl_product_id --Conectar sku con la tarjeta\n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_sku\"               bs2     ON bs2.sku_id = bp.default_sku_id --Conectar la tarjeta con el sku que guarda la info\n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_category_xref\"     bcx     ON bcx.sub_category_id = bp.default_category_id AND bcx.archived='N' AND bcx.sndbx_tier is NULL --Relaciones categorias \n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_category\"          bcat    ON bp.default_category_id = bcat.category_id --Nombre subcategoria\n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_category\"          bcat2   ON bcx.category_id = bcat2.category_id --Nombre categoria\n",
    "\n",
    "where\n",
    "  p.deleted_at is null\n",
    "  and p.parent_id is null\n",
    "  and bs.archived = 'N'\n",
    "  and bs.sndbx_id is null\n",
    "  and bp.archived = 'N'\n",
    "  and bs.catalog_disc < 0\n",
    "  and ((bp.archived = 'N' and bp.sndbx_id is null) or (bp.archived is null))\n",
    "  \"\"\"\n",
    "df_aux1 = read_connection_data_warehouse.runQuery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_margen = pd.merge(df_margen[['region','sku','margin']], df_aux1[['sku','card_name','card_id']],  how='inner', left_on=['sku'], right_on = ['sku'])\n",
    "df_margen = df_margen.dropna()\n",
    "df_margen = df_margen.groupby(['region','card_id','card_name']).margin.mean().reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "s.identifier_value AS city,\n",
    "DATE(fs.order_submitted_date) AS submit_date,\n",
    "fs.order_id,\n",
    "dc.source_id AS customer_id,\n",
    "cat.parent_description as category,\n",
    "cat.description AS subcategory,\n",
    "dp.card_id,\n",
    "dp.card_description AS product_name,\n",
    "fs.product_quantity_x_step_unit AS cant,\n",
    "CASE\n",
    "    WHEN s.identifier_value IN ('SPO','BHZ','CWB','VCP') THEN fs.gmv_pxq_local/4.75\n",
    "    WHEN s.identifier_value IN ('BOG','BAQ','MDE') THEN fs.gmv_pxq_local/3776\n",
    "    WHEN s.identifier_value IN ('CMX') THEN fs.gmv_pxq_local/19.65\n",
    "    ELSE fs.gmv_pxq_local\n",
    "END AS gmv_usd,\n",
    "CASE\n",
    "    WHEN s.identifier_value IN ('SPO','BHZ','CWB','VCP') THEN fsd.product_discount/4.75\n",
    "    WHEN s.identifier_value IN ('BOG','BAQ','MDE') THEN fsd.product_discount/3776\n",
    "    WHEN s.identifier_value IN ('CMX') THEN fsd.product_discount/19.65\n",
    "    ELSE fsd.product_discount\n",
    "END AS discount_applied\n",
    "FROM dpr_sales.fact_sales                   fs\n",
    "INNER JOIN dpr_shared.dim_customer          dc  ON dc.customer_id = fs.dim_customer\n",
    "INNER JOIN dpr_shared.dim_site              s   ON s.site_id = fs.dim_site\n",
    "INNER JOIN dpr_shared.dim_product           dp  ON dp.product_id = fs.dim_product\n",
    "INNER JOIN dpr_shared.dim_category          cat ON cat.category_id = dp.category_id\n",
    "LEFT JOIN dpr_sales.fact_sales_discounts    fsd ON fs.order_item_id = fsd.order_item_id \n",
    "WHERE fs.gmv_enabled = TRUE\n",
    "AND fulfillment_order_status NOT IN ('CANCELLED', 'ARCHIVED','No value')\n",
    "AND fs.fb_order_status_id  IN (1,6,7,8)\n",
    "AND fs.is_deleted = FALSE\n",
    "AND fs.dim_status = 1\n",
    "AND dp.is_slot = 'false'\n",
    "AND s.identifier_value IN ('BOG','BAQ','MDE','CMX','SPO','BHZ','CWB','VCP')\n",
    "--AND s.identifier_value = '{city}'\n",
    "AND dc.source_id IN {clientes}\n",
    "\"\"\".format(clientes=tuple(df_kams_ctm.customer_id.unique()), city = city)\n",
    "\n",
    "data_ventas_aux = run_read_dwd_query(query)\n",
    "data_ventas_aux[[\"gmv_usd\", \"cant\",\"discount_applied\"]] = data_ventas_aux[[\"gmv_usd\", \"cant\",\"discount_applied\"]].astype(float)\n",
    "data_ventas_aux['submit_date'] = pd.to_datetime(data_ventas_aux['submit_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_ventas_aux.loc[data_ventas_aux.card_id.isin(df_skus.card_id.unique())].groupby(by=['city','customer_id','submit_date','category','subcategory','card_id','product_name']).agg({'gmv_usd':'sum','cant':'sum','discount_applied':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for the whole kam behavior\n",
    "df_all = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacion de df con info by product by client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('submit_date',ignore_index=True)\n",
    "\n",
    "#fix for id problems and taking into account only dates\n",
    "df['order_id']= df.submit_date.apply(lambda x:x.toordinal()) \n",
    "\n",
    "#Days of difference between orders for customer and for cat\n",
    "df['days_bet'] = (df.submit_date -df.groupby('customer_id').submit_date.transform('min')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This calculate in res the difference between consecutive orders and with the agg we calculate all metrics\n",
    "df['res'] = df.groupby(by=['customer_id', 'card_id', 'product_name'])['days_bet'].diff()\n",
    "df_grouped = df.groupby(by=['city', 'customer_id', 'card_id', 'product_name']).agg({'res': [np.min, np.max, np.mean, np.median, np.std],\n",
    "                                                                                    'order_id': [lambda x: x.nunique()], \n",
    "                                                                                    'gmv_usd': [np.sum, np.mean],\n",
    "                                                                                    'discount_applied': [np.sum, np.mean],\n",
    "                                                                                    'cant': [np.sum, np.mean],\n",
    "                                                                                    'submit_date': [np.max, lambda x: (x.max()-x.min()).days, lambda x: (datetime.datetime.today() - x.max()).days, np.min]\n",
    "                                                                                    }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we define everything in a df2 for further processing\n",
    "df2 = df_grouped.copy()\n",
    "\n",
    "df2.columns = ['city', 'customer_id', 'card_id', 'product_name', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
    "               'num_orders', 'gmv_cat_usd','aov_cat_usd', 'all_dct_usd', 'avg_dct_usd','all_cant_cat','avg_cant_cat', 'last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order','first_order_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df2, df_margen[['card_id','margin']],  how='left', left_on=['card_id'], right_on = ['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['margin'].fillna(0.1, inplace=True)\n",
    "df2['avg_cash_margin'] = df2.aov_cat_usd * df2.margin\n",
    "df2['all_cash_margin'] = df2.gmv_cat_usd * df2.margin\n",
    "df2['avg_net_cash_margin'] = df2.avg_cash_margin - df2.avg_dct_usd\n",
    "df2['all_net_cash_margin'] = df2.all_cash_margin - df2.all_dct_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"churned\"] = [0 if ((x[18]) - (x[6]+x[8]*2) <= 0) else 1 for x in df2.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['churned_date'] = df2.apply(lambda x: (x[16] + datetime.timedelta(days=int(x[6]) + int(x[8]) * 2)).strftime('%Y-%m-%d') if not (pd.isnull(x[6]) or pd.isnull(x[8])) else None, axis=1)\n",
    "df2['churned_date'] = pd.to_datetime(df2['churned_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genracion df y info by customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, df_margen[['card_id','margin']],  how='left', left_on=['card_id'], right_on = ['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['margin'].fillna(0.05, inplace=True)\n",
    "df_all['cash_margin'] = df_all.gmv_usd * df_all.margin\n",
    "df_all['net_cash_margin'] = df_all.cash_margin - df_all.discount_applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.sort_values('submit_date',ignore_index=True)\n",
    "\n",
    "#fix for id problems and taking into account only dates\n",
    "df_all['order_id']= df_all.submit_date.apply(lambda x:x.toordinal()) \n",
    "\n",
    "#Days of difference between orders for customer and for cat\n",
    "df_all['days_bet'] = (df_all.submit_date -df_all.groupby('customer_id').submit_date.transform('min')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This calculate in res the difference between consecutive orders and with the agg we calculate all metrics\n",
    "df_all['res'] = df_all.groupby(by=['customer_id', 'card_id', 'product_name'])['days_bet'].diff()\n",
    "df_grouped_all = df_all.groupby(by=['city', 'customer_id']).agg({'res': [np.min, np.max, np.mean, np.median, np.std],\n",
    "                                                                 'order_id': [lambda x: x.nunique()], \n",
    "                                                                 'gmv_usd': [np.sum, np.mean],\n",
    "                                                                 'discount_applied': [np.sum, np.mean],\n",
    "                                                                 'cash_margin': [np.sum, np.mean],\n",
    "                                                                 'cant': [np.sum, np.mean],\n",
    "                                                                 'submit_date': [np.max, lambda x: (x.max()-x.min()).days, lambda x: (datetime.datetime.today() - x.max()).days, np.min]\n",
    "                                                                 }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we define everything in a df2 for further processing\n",
    "df2_all = df_grouped_all.copy()\n",
    "\n",
    "df2_all.columns = ['city', 'customer_id', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
    "               'num_orders', 'gmv_cat_usd','aov_cat_usd', 'all_dct_usd', 'avg_dct_usd', 'all_cash_margin', 'avg_cash_margin','all_cant_cat','avg_cant_cat', 'last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order','first_order_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_all['adjust_std'] = pd.qcut(df2_all.stdev_diff_days, 10, labels=[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])\n",
    "df2_all[[\"adjust_std\"]] = df2_all[[\"adjust_std\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_all[\"cltv\"] = 1000.00 * df2_all.all_cash_margin * df2_all.adjust_std * df2_all.num_orders / df2_all.diff_from_last_to_first_order\n",
    "df2_all['cltv'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the percentiles for tiers\n",
    "percentiles = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "tier_labels = ['E', 'D', 'C', 'B', 'A']\n",
    "\n",
    "# Add a new column with the tier labels based on percentiles\n",
    "df2_all['tier'] = df2_all.loc[df2_all.city.isin(['BOG','BAQ','MDE','CMX','SPO','BHZ','CWB','VCP'])].groupby('city')['cltv'].transform(lambda x: pd.qcut(x, q=percentiles, labels=tier_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_all[\"all_churned\"] = [0 if ((x[18]) - (x[4]+x[6]*2) <= 0) else 1 for x in df2_all.values]\n",
    "df2_all['all_churned_date'] = df2_all.apply(lambda x: (x[16] + datetime.timedelta(days=int(x[4]) + int(x[6]) * 2)).strftime('%Y-%m-%d') if not (pd.isnull(x[4]) or pd.isnull(x[6])) else None, axis=1)\n",
    "df2_all['all_churned_date'] = pd.to_datetime(df2_all['all_churned_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRING NAME AND RESPONSABLE OF THE KAM\n",
    "df3 = pd.merge(df2, df_kams_ctm[['customer_id','user_name','kam_name','status']],  how='left', left_on=['customer_id'], right_on = ['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRING CHURN ALL DATE OF THE KAM\n",
    "df3 = pd.merge(df3, df2_all[['customer_id','all_churned','all_churned_date','cltv','tier']],  how='left', left_on=['customer_id'], right_on = ['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRING CATEGORY AND STATUS FRIDA\n",
    "df3 = pd.merge(df3, df_skus[['card_id','categoria','subcategoria','status_frida']],  how='left', left_on=['card_id'], right_on = ['card_id'])\n",
    "\n",
    "df3[['categoria']] = df3[['categoria']].fillna('DELETED')\n",
    "df3[['subcategoria']] = df3[['subcategoria']].fillna('DELETED')\n",
    "df3[['status_frida']] = df3[['status_frida']].fillna('DELETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df3, df_prices,  how='left', left_on=['card_id'], right_on = ['card_id'])\n",
    "df3 = pd.merge(df3, df_no_filt_offers[['card_id','dct']],  how='left', left_on=['card_id'], right_on = ['card_id'])\n",
    "df3 = pd.merge(df3, df_filt_offers[['customer_id','card_id','dct']],  how='left', left_on=['customer_id','card_id'], right_on = ['customer_id','card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['dct_x'].fillna(0, inplace=True)\n",
    "df3['dct_y'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['net_price_all'] = (df3.gross_price_no_iva * (1-df3.dct_x)) + (df3.gross_price - df3.gross_price_no_iva)\n",
    "df3['net_price_spfc'] = (df3.gross_price_no_iva * (1-df3.dct_y)) + (df3.gross_price - df3.gross_price_no_iva)\n",
    "\n",
    "df3['gpi'] = 100.00 * df3.gross_price / df3.benchmark\n",
    "df3['npi_all'] = 100.00 * df3.net_price_all / df3.benchmark\n",
    "df3['npi_spfc'] = 100.00 * df3.net_price_spfc / df3.benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['best_net_price'] = np.maximum(df3['net_price_all'].fillna(-1), df3['net_price_spfc'].fillna(-1))\n",
    "df3['best_npi'] = np.maximum(df3['npi_all'].fillna(-1), df3['npi_spfc'].fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date\n",
    "current_date = datetime.datetime.now()\n",
    "\n",
    "# Calculate the start and end dates of the current week\n",
    "start_of_week = current_date - timedelta(days=current_date.weekday())\n",
    "end_of_week = start_of_week + timedelta(days=6)\n",
    "current_date2 = datetime.datetime.now().strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current date, last month, and the month before last\n",
    "last_month = current_date - timedelta(days=30)\n",
    "month_before_last = current_date - timedelta(days=60)  # Two months before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.loc[(df3.benchmark>0) & (df3.status_frida == 'on') & (df3.churned_date >= month_before_last) & (df3.churned_date <= current_date)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_city = df3.city.isin(['CMX', 'BAQ', 'BOG', 'MDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions for both cases\n",
    "condition_with_100 = (df3.gpi - df3.margin * 100.00 * 0.85 < 95) & \\\n",
    "                     (df3.best_npi > 95)\n",
    "\n",
    "condition_with_95 = (df3.gpi - df3.margin * 100.00 * 0.85 < 95) & \\\n",
    "                    (df3.best_npi > 95)\n",
    "                    \n",
    "# Apply the conditions using np.where and filter df_dct\n",
    "df_dct = df3.copy()\n",
    "df_dct['condition'] = np.where(condition_city, condition_with_100, condition_with_95)\n",
    "df_dct = df_dct[df_dct['condition']].copy()\n",
    "df_dct.drop(columns=['condition'], inplace=True)\n",
    "\n",
    "condition_city = df_dct.city.isin(['CMX', 'BAQ', 'BOG', 'MDE'])\n",
    "# Calculate the 'dct' column conditionally\n",
    "df_dct['dct'] = np.where(condition_city,  # Apply the condition to df_dct\n",
    "                         np.round((1 - (df_dct.benchmark * 0.95 / df_dct.gross_price)) * 100.00, 2),\n",
    "                         np.round((1 - (df_dct.benchmark * 0.95 / df_dct.gross_price)) * 100.00, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dct['dct'] = np.round((1 - (df_dct.benchmark * 0.99 / df_dct.gross_price)) * 100.00,2)\n",
    "df_dct['proportion_dct'] = np.round(df_dct.dct_x / (df_dct.dct/100.00),2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dct = df_dct.loc[(df_dct.proportion_dct < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df.loc[(df.customer_id.isin(df_dct.customer_id.unique())) & (df.card_id.isin(df_dct.card_id.unique()))].groupby([\"city\",\"customer_id\"]).agg({'gmv_usd':np.sum,'card_id': lambda x: x.nunique()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_groups(offer):\n",
    "    customers = offer.customer_id.unique()\n",
    "    \n",
    "    alpha = 0.01\n",
    "    aux = 0\n",
    "    \n",
    "    while True:\n",
    "        customer_control, customer_test = train_test_split(customers, test_size=0.50)\n",
    "        \n",
    "        avg_gmv_control = offer[offer.customer_id.isin(customer_control)]['gmv_usd'].mean()\n",
    "        avg_gmv_test = offer[offer.customer_id.isin(customer_test)]['gmv_usd'].mean()\n",
    "        \n",
    "        avg_products_control = offer[offer.customer_id.isin(customer_control)]['card_id'].mean()\n",
    "        avg_products_test = offer[offer.customer_id.isin(customer_test)]['card_id'].mean()\n",
    "        \n",
    "        # Check if both average GMV and average products meet the criteria\n",
    "        if (\n",
    "            abs(1 - (avg_gmv_control / avg_gmv_test)) <= alpha and\n",
    "            abs(1 - (avg_products_control / avg_products_test)) <= alpha\n",
    "        ):\n",
    "            break\n",
    "        \n",
    "        aux += 1\n",
    "        \n",
    "        if aux == 1000:\n",
    "            alpha += 0.01\n",
    "            aux = 0\n",
    "    print(alpha)\n",
    "    return customer_control.tolist(), customer_test.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.02\n",
      "0.01\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "result_rows = []\n",
    "for city in df_groups.city.unique():\n",
    "    control, piloto = create_groups(df_groups.loc[df_groups.city == city])\n",
    "    \n",
    "    for customer_id in control:\n",
    "        result_rows.append([city, customer_id, 'control'])\n",
    "    \n",
    "    for customer_id in piloto:\n",
    "        result_rows.append([city, customer_id, 'piloto'])\n",
    "\n",
    "result_df = pd.DataFrame(result_rows, columns=['city', 'customer_id', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dct2 = pd.merge(df_dct, result_df,  how='left', left_on=['city','customer_id'], right_on = ['city','customer_id'])\n",
    "df_dct3 = pd.merge(df_dct, result_df,  how='left', left_on=['city','customer_id'], right_on = ['city','customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dct2 = df_dct2.loc[df_dct2.group == 'piloto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dct2[\"offer_name\"] = (\n",
    "    \"KAM_PTOOL_EXP.DCT_\" +\n",
    "    df_dct2[\"city\"] + \"_\" +\n",
    "    df_dct2[\"product_name\"].str.replace(\",\", \".\") + \"_\" + current_date2 + \"_\" +\n",
    "    df_dct2[\"dct\"].astype(str) + \"%_HDCT_\" + \n",
    "    df_dct2[\"proportion_dct\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments(offer, cityy):\n",
    "        import requests\n",
    "        import json\n",
    "        \n",
    "        global_segment_list = [] #//for procesing\n",
    "        for i in offer.customer_id.unique():\n",
    "                segment = {'name':str(i), 'customersIds': [int(i)],\"expiresAt\": (datetime.datetime.today() + datetime.timedelta(days=(7))).strftime('%Y-%m-%d')}\n",
    "                global_segment_list.append(segment) \n",
    "        \n",
    "        url = f\"https://{cityy}.frubana.com/api/v1/segments/create?api-key=00_growth-team-zzz-qqq_001\"\n",
    "\n",
    "        payload = json.dumps(global_segment_list)\n",
    "\n",
    "\n",
    "        headers = {\n",
    "        'Cookie': 'AWSALB=WGKrKvA1CFOY0m92xSENGAseuE4LrcfQh9y8jK/loGBJdizNm+FvjOqUqVghxdfLkH6Jsa9sfWft2NELchGAP/LNZMXMYhrOE70qDnUuOHATpdJj1UZBMEUBSIN1; AWSALBCORS=WGKrKvA1CFOY0m92xSENGAseuE4LrcfQh9y8jK/loGBJdizNm+FvjOqUqVghxdfLkH6Jsa9sfWft2NELchGAP/LNZMXMYhrOE70qDnUuOHATpdJj1UZBMEUBSIN1; AWSALB=jLY02FPysvF1vTrKLhXbk3ibzmyiAqFJ1ezYVu5PjodkU2QmPHDpRJhb9CvOlOyQ1Ix0mJR1ig+eH9zwJ9i5EOtgsgx79NSROogQb2Ua6yLX/I3bJJ6xtcVO3puI; AWSALBCORS=jLY02FPysvF1vTrKLhXbk3ibzmyiAqFJ1ezYVu5PjodkU2QmPHDpRJhb9CvOlOyQ1Ix0mJR1ig+eH9zwJ9i5EOtgsgx79NSROogQb2Ua6yLX/I3bJJ6xtcVO3puI',\n",
    "        'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "        \n",
    "        sgt = [(int(x[:6]),x[7:]) for x in list(map(str.strip, response.text[32:].strip('][').replace('\"', '').split(',')))]\n",
    "        ssgtt = pd.DataFrame(sgt, columns=['segment_id', 'customer_id'])\n",
    "        ssgtt[[\"customer_id\"]] = ssgtt[[\"customer_id\"]].astype(int)\n",
    "        \n",
    "        return ssgtt                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_files(offer,segment):\n",
    "    csv_file = {} \n",
    "    csv_file['offer_name'] = offer.offer_name\n",
    "    csv_file['offer_description'] = None\n",
    "    csv_file['discount'] = offer.dct\n",
    "    csv_file['automatically_consider_offer'] = \"true\"\n",
    "    csv_file['start_date'] = (datetime.datetime.today() + datetime.timedelta(days=0)).strftime('%d-%m-%Y')\n",
    "    csv_file['end_date'] = (datetime.datetime.today() + datetime.timedelta(days=(7))).strftime('%d-%m-%Y')\n",
    "    csv_file['max_uses_per_order'] = 0\n",
    "    csv_file['max_uses_per_customer'] = 2\n",
    "    csv_file['customer_segment_id'] = [segment.loc[segment.customer_id == customer].segment_id.unique()[0] for customer in offer.customer_id]\n",
    "\n",
    "    sku_ids = []\n",
    "    for sku in offer.card_id:\n",
    "        try:\n",
    "            sku_id = frida_products.loc[frida_products.id_tarjeta == sku, \"skus\"].values[0]\n",
    "        except IndexError:\n",
    "            sku_id = None  # Assign a null value if IndexError occurs\n",
    "        sku_ids.append(sku_id)\n",
    "    \n",
    "    csv_file['sku_id'] = sku_ids\n",
    "    \n",
    "    df = pd.DataFrame(csv_file)\n",
    "    \n",
    "    # Drop rows with null values in the 'sku_id' column\n",
    "    df = df.dropna(subset=['sku_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dct3.to_csv(f\"grupos_KAM_{current_date2}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAQ\n",
      "BHZ\n",
      "BOG\n",
      "CMX\n",
      "CWB\n",
      "MDE\n",
      "SPO\n",
      "VCP\n"
     ]
    }
   ],
   "source": [
    "for city in df_dct2.city.unique():\n",
    "    print(city)\n",
    "    \n",
    "    segment = segments(df_dct2.loc[df_dct2.city == city],city)\n",
    "    \n",
    "    city_csv = csv_files(df_dct2.loc[df_dct2.city == city],segment)\n",
    "    city_csv = city_csv.drop_duplicates()\n",
    "    city_csv.to_csv(f\"{city}_KAM_EXP.DCT{current_date2}.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "624741679a3ae5d99cecf49b8df5d516a7a937e6e7328e129d1fa121c8592e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
