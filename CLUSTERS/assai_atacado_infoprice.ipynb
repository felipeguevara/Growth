{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//----------------------------\n",
    "#//LIBRARIES\n",
    "    #Math\n",
    "import math\n",
    "    #Numeric Python\n",
    "import numpy as np\n",
    "    #Pandas (dataframes)\n",
    "import pandas as pd\n",
    "    #datetime for fate manipulation\n",
    "from datetime import date, datetime, timedelta  \n",
    "    #Regex for advanced string matching\n",
    "import re\n",
    "    #for time related stuff\n",
    "import time \n",
    "    #json library\n",
    "import json\n",
    "    #Analyst tools\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from analysts_tools.growth import *\n",
    "    #Procurement tools\n",
    "from procurement_lib import send_slack_notification\n",
    "from procurement_lib import redash\n",
    "from analysts_tools.redash_methods import *\n",
    "from analystcommunity.read_connection_data_warehouse import run_read_dwd_query, run_read_prod_query\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from procurement_lib import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtin = GoogleSheet(\"1TBAwmxAoqg6FX79d7wLu3DVtIiOb6gRfkN5fMA_tLNc\")\n",
    "df_gtin = df_gtin.get_as_dataframe('Hoja 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"info_assai_atacado.csv\")\n",
    "df['quotation_date'] = pd.to_datetime(df['quotation_date'])\n",
    "df[['gtin']] = df[['gtin']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df, df_gtin, left_on=['gtin','site_code'], right_on=['GTIN','city'], how='left')\n",
    "df2 = df2.drop(['city', 'GTIN'], axis=1)\n",
    "df2 = df2.dropna().reset_index(drop=True)\n",
    "\n",
    "df2['lifetime'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dataframe is sorted by 'quotation_date'\n",
    "df2 = df2.sort_values(by='quotation_date')\n",
    "\n",
    "# Generate the required rows for missing dates\n",
    "new_rows = []\n",
    "\n",
    "for (competitor, source_id), group in df2.groupby(['competitor_name', 'source_id']):\n",
    "    group = group.sort_values(by='quotation_date')\n",
    "    last_known_price = None\n",
    "    last_known_date = None\n",
    "    lifetime = 8\n",
    "    \n",
    "    for current_index in range(len(group)):\n",
    "        current_date = group.iloc[current_index]['quotation_date']\n",
    "        price = group.iloc[current_index]['price']\n",
    "        \n",
    "        # If this is not the first iteration, fill in missing dates\n",
    "        if last_known_date is not None:\n",
    "            days_diff = (current_date - last_known_date).days\n",
    "            if days_diff > 1:\n",
    "                for j in range(1, min(days_diff, lifetime + 1)):\n",
    "                    new_date = last_known_date + timedelta(days=j)\n",
    "                    new_row = {\n",
    "                        'site_code': group.iloc[current_index]['site_code'],\n",
    "                        'quotation_date': new_date,\n",
    "                        'dim_quotation_date': int(new_date.strftime('%Y%m%d')),\n",
    "                        'competitor_name': competitor,\n",
    "                        'source_id': source_id,\n",
    "                        'product_name': group.iloc[current_index]['product_name'],\n",
    "                        'price': last_known_price,\n",
    "                        'lifetime': lifetime - j\n",
    "                    }\n",
    "                    new_rows.append(new_row)\n",
    "                    \n",
    "                    # Stop if we reach a new datapoint date\n",
    "                    if new_date + timedelta(days=1) == current_date:\n",
    "                        break\n",
    "        \n",
    "        # Update the last known values and reset lifetime\n",
    "        last_known_price = price\n",
    "        last_known_date = current_date\n",
    "        lifetime = 8  # Reset lifetime\n",
    "\n",
    "    # After processing all known dates for the group, continue generating rows until lifetime reaches 0\n",
    "    while lifetime > 0:\n",
    "        last_known_date += timedelta(days=1)\n",
    "        new_row = {\n",
    "            'site_code': group.iloc[-1]['site_code'],\n",
    "            'quotation_date': last_known_date,\n",
    "            'dim_quotation_date': int(last_known_date.strftime('%Y%m%d')),\n",
    "            'competitor_name': competitor,\n",
    "            'source_id': source_id,\n",
    "            'product_name': group.iloc[-1]['product_name'],\n",
    "            'price': last_known_price,\n",
    "            'lifetime': lifetime - 1\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "        lifetime -= 1\n",
    "\n",
    "# Append new rows to the dataframe\n",
    "df2 = df2.append(new_rows, ignore_index=True)\n",
    "\n",
    "# Sort the final dataframe\n",
    "df2 = df2.sort_values(by=['competitor_name', 'source_id', 'quotation_date'])\n",
    "df2['replica'] = df2['lifetime'] == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['site_code', 'quotation_date', 'competitor_name', 'price',\n",
    "       'source_id', 'product_name']].to_csv(\"all_infoprice_info_no_out_by_store.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = pd.read_csv(\"all_infoprice_info_no_out_by_store.csv\")\n",
    "\n",
    "# Convert the quotation_date column to datetime format\n",
    "df_bench['quotation_date'] = pd.to_datetime(df_bench['quotation_date'])\n",
    "df_bench['product_name'] = df_bench['site_code'] + \" || \" + df_bench['product_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH RECURSIVE calendar(calendar_date) AS (\n",
    "  SELECT DATE_TRUNC('day', DATE(GETDATE()) - INTERVAL '700 day')\n",
    "  UNION ALL\n",
    "  SELECT calendar_date + INTERVAL '1 day'\n",
    "  FROM calendar\n",
    "  WHERE calendar_date BETWEEN DATE_TRUNC('day', DATE(GETDATE()) - INTERVAL '700 day') AND DATE(GETDATE() - 1) \n",
    "),\n",
    "\n",
    "info AS (\n",
    "SELECT\n",
    "    DATE(coalesce(prices.last_modified_at, prices.created_at)) as created_at,\n",
    "    pp.frida_id as source_id,\n",
    "    MIN(coalesce(tiers.tax_price, prices.tax_price)) as price,\n",
    "    MIN(coalesce(tiers.sale_price, prices.sale_price)) as net_price\n",
    "\n",
    "FROM postgres_growth.\"growth_pricing.prices_history\" prices\n",
    "LEFT JOIN postgres_growth.\"growth_pricing.price_tiers_history\" tiers ON prices.id = tiers.price_history_id\n",
    "LEFT JOIN postgres_growth.\"growth_pricing.skus\" skus ON prices.sku_id = skus.id\n",
    "LEFT JOIN postgres_main_co.\"purchase_orders.products\" p ON skus.sku_id = p.frida_id\n",
    "LEFT JOIN postgres_main_co.\"purchase_orders.products\" pp ON COALESCE(p.parent_id, p.id) = pp.id\n",
    "\n",
    "WHERE DATE(prices.created_at) >= DATE_TRUNC('day', DATE(GETDATE()) - INTERVAL '700 day')\n",
    " AND p.region_code IN ('SPO','BHZ','CWB','VCP')\n",
    " AND p.deleted_at IS NULL\n",
    " AND prices.created_by NOT ILIKE '%CATALOG%'\n",
    " AND pp.product_category_id IN (5,6,7,8,9,10,13,18) -- 1 ES FRUVER\n",
    " AND pp.frida_id IN {skus}\n",
    "GROUP BY 1,2--,3,4\n",
    "),\n",
    "\n",
    "done AS (\n",
    "SELECT\n",
    "  DATE(c.calendar_date) AS quotation_date,\n",
    "  --s.region,\n",
    "  --s.parent_product_name,\n",
    "  (s.source_id)::int as source_id,\n",
    "  LAG(i.price IGNORE NULLS) OVER (PARTITION BY s.source_id ORDER BY c.calendar_date)::FLOAT AS p_price_tool,\n",
    "  LAG(i.net_price IGNORE NULLS) OVER (PARTITION BY s.source_id ORDER BY c.calendar_date)::FLOAT AS net_price_tool\n",
    "\n",
    "\n",
    "FROM calendar c\n",
    "CROSS JOIN (SELECT DISTINCT source_id FROM info) s\n",
    "LEFT JOIN info i ON c.calendar_date = i.created_at-1 AND s.source_id = i.source_id\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM done\n",
    "WHERE net_price_tool IS NOT NULL\n",
    " AND quotation_date >= '2024-02-10'\n",
    " AND quotation_date <= '2024-05-22'\n",
    "\"\"\".format(skus=tuple(df_bench.source_id.unique()))\n",
    "df = run_read_prod_query(query)  \n",
    "df['quotation_date'] = pd.to_datetime(df['quotation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_bench, df, left_on=['source_id','quotation_date'], right_on=['source_id','quotation_date'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    s.identifier_value AS site_code,\n",
    "    DATE(fs.order_submitted_date) AS quotation_date,\n",
    "    sup.source_id,\n",
    "    (SUM(fs.gmv_pxq_local)/4.75)::FLOAT AS gmv_usd,\n",
    "    gmv_usd/SUM(gmv_usd) OVER (PARTITION BY s.identifier_value)::FLOAT AS gmv_mix,\n",
    "    AVG(COALESCE(inventory_p_fin,cogs_p_day))::FLOAT AS costo\n",
    "\n",
    "FROM dpr_sales.fact_sales                   fs\n",
    "INNER JOIN dpr_shared.dim_site              s   ON s.site_id = fs.dim_site\n",
    "INNER JOIN dpr_shared.dim_product           dp  ON dp.product_id = fs.dim_product\n",
    "INNER JOIN dpr_shared.dim_category          cat ON cat.category_id = dp.category_id\n",
    "INNER JOIN dpr_shared.dim_stock_unit        su  ON su.product_id = fs.dim_product\n",
    "INNER JOIN dpr_shared.dim_stock_unit        sup  ON nvl(nullif(su.source_parent_id,0),su.source_id) = sup.source_id\n",
    "LEFT JOIN dpr_cross_business.fact_cross_business_insights m ON m.dim_stock_unit = sup.stock_unit_id AND m.dim_date = fs.dim_submitted_date\n",
    "\n",
    "WHERE \n",
    "    fs.gmv_enabled = TRUE\n",
    "    AND fulfillment_order_status NOT IN ('CANCELLED', 'ARCHIVED','No value')\n",
    "    AND fs.fb_order_status_id IN (1,6,7,8)\n",
    "    AND fs.is_deleted = FALSE\n",
    "    AND cat.super_category = 'Multicategoría'\n",
    "    AND fs.dim_status = 1\n",
    "    AND dp.is_slot = 'false'\n",
    "    AND fs.gmv_pxq_local > 0\n",
    "    AND s.identifier_value IN ('SPO','CWB','VCP','BHZ')\n",
    "    AND DATE(fs.order_submitted_date) >= '2024-02-10'\n",
    "    AND DATE(fs.order_submitted_date) <= '2024-05-22'\n",
    "GROUP BY 1,2,3\n",
    "HAVING costo > 0\n",
    "\"\"\"\n",
    "df_gmv = run_read_dwd_query(query)\n",
    "df_gmv['quotation_date'] = pd.to_datetime(df_gmv['quotation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assai = pd.merge(df_gmv, df.loc[df.competitor_name=='Assai Atacadista'], left_on=['site_code','source_id','quotation_date'], right_on=['site_code','source_id','quotation_date'], how='left')\n",
    "df_atacado = pd.merge(df_gmv, df.loc[df.competitor_name=='Atacadão'], left_on=['site_code','source_id','quotation_date'], right_on=['site_code','source_id','quotation_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assai['gpi'] = df_assai.p_price_tool/df_assai.price\n",
    "df_assai['npi'] = df_assai.net_price_tool/df_assai.price\n",
    "\n",
    "df_assai['mg'] = 1-(df_assai.costo/df_assai.p_price_tool)\n",
    "df_assai['nmg'] = 1-(df_assai.costo/df_assai.net_price_tool)\n",
    "\n",
    "df_assai['comp_mg'] = 1-(df_assai.costo/df_assai.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atacado['gpi'] = df_atacado.p_price_tool/df_atacado.price\n",
    "df_atacado['npi'] = df_atacado.net_price_tool/df_atacado.price\n",
    "\n",
    "df_atacado['mg'] = 1-(df_atacado.costo/df_atacado.p_price_tool)\n",
    "df_atacado['nmg'] = 1-(df_atacado.costo/df_atacado.net_price_tool)\n",
    "\n",
    "df_atacado['comp_mg'] = 1-(df_atacado.costo/df_atacado.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFOPRICE -ASSAI INFO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_code</th>\n",
       "      <th>gmv_mix</th>\n",
       "      <th>skus</th>\n",
       "      <th>mg</th>\n",
       "      <th>nmg</th>\n",
       "      <th>comp_mg</th>\n",
       "      <th>gpi</th>\n",
       "      <th>npi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHZ</td>\n",
       "      <td>41.298247</td>\n",
       "      <td>218.0</td>\n",
       "      <td>8.722071</td>\n",
       "      <td>4.279626</td>\n",
       "      <td>5.566946</td>\n",
       "      <td>103.951868</td>\n",
       "      <td>99.420635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CWB</td>\n",
       "      <td>17.643829</td>\n",
       "      <td>110.0</td>\n",
       "      <td>8.982334</td>\n",
       "      <td>5.435905</td>\n",
       "      <td>4.757701</td>\n",
       "      <td>104.805434</td>\n",
       "      <td>100.968994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPO</td>\n",
       "      <td>58.192791</td>\n",
       "      <td>428.0</td>\n",
       "      <td>9.347103</td>\n",
       "      <td>6.644135</td>\n",
       "      <td>11.960858</td>\n",
       "      <td>97.216553</td>\n",
       "      <td>94.543421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCP</td>\n",
       "      <td>46.153851</td>\n",
       "      <td>253.0</td>\n",
       "      <td>8.601947</td>\n",
       "      <td>5.315976</td>\n",
       "      <td>11.483292</td>\n",
       "      <td>96.941102</td>\n",
       "      <td>93.659933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_code    gmv_mix   skus        mg       nmg    comp_mg         gpi  \\\n",
       "0       BHZ  41.298247  218.0  8.722071  4.279626   5.566946  103.951868   \n",
       "1       CWB  17.643829  110.0  8.982334  5.435905   4.757701  104.805434   \n",
       "2       SPO  58.192791  428.0  9.347103  6.644135  11.960858   97.216553   \n",
       "3       VCP  46.153851  253.0  8.601947  5.315976  11.483292   96.941102   \n",
       "\n",
       "          npi  \n",
       "0   99.420635  \n",
       "1  100.968994  \n",
       "2   94.543421  \n",
       "3   93.659933  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to apply the custom aggregation\n",
    "def custom_ventas(group, column):\n",
    "    return (100.00 * group[column] * group['gmv_mix']).sum()/group['gmv_mix'].sum()\n",
    "merge_df2 = df_assai.dropna(how='any')\n",
    "# Group by 'city' and 'year_week', aggregate multiple columns with custom aggregation\n",
    "df_final_assai = merge_df2.groupby(['site_code']).apply(lambda group: pd.Series({\n",
    "    'gmv_mix': 100.00*group['gmv_mix'].sum(),  # Compute sum of gmv_mix directly\n",
    "    'skus': group['source_id'].nunique(),\n",
    "    'mg': custom_ventas(group, 'mg'),\n",
    "    'nmg': custom_ventas(group, 'nmg'),\n",
    "    'comp_mg': custom_ventas(group, 'comp_mg'),\n",
    "    'gpi': custom_ventas(group, 'gpi'),\n",
    "    'npi': custom_ventas(group, 'npi')\n",
    "})).reset_index()\n",
    "print('INFOPRICE -ASSAI INFO:')\n",
    "df_final_assai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFOPRICE -ATACADAO INFO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_code</th>\n",
       "      <th>gmv_mix</th>\n",
       "      <th>skus</th>\n",
       "      <th>mg</th>\n",
       "      <th>nmg</th>\n",
       "      <th>comp_mg</th>\n",
       "      <th>gpi</th>\n",
       "      <th>npi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHZ</td>\n",
       "      <td>37.445107</td>\n",
       "      <td>184.0</td>\n",
       "      <td>8.614564</td>\n",
       "      <td>3.492398</td>\n",
       "      <td>9.504738</td>\n",
       "      <td>99.273602</td>\n",
       "      <td>94.320159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CWB</td>\n",
       "      <td>23.828168</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.194811</td>\n",
       "      <td>5.891820</td>\n",
       "      <td>6.548380</td>\n",
       "      <td>103.697914</td>\n",
       "      <td>100.451990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPO</td>\n",
       "      <td>54.885213</td>\n",
       "      <td>415.0</td>\n",
       "      <td>9.652923</td>\n",
       "      <td>6.782515</td>\n",
       "      <td>4.529234</td>\n",
       "      <td>105.876297</td>\n",
       "      <td>102.693496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCP</td>\n",
       "      <td>37.923383</td>\n",
       "      <td>243.0</td>\n",
       "      <td>9.378060</td>\n",
       "      <td>6.025572</td>\n",
       "      <td>13.577839</td>\n",
       "      <td>95.478007</td>\n",
       "      <td>92.148891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_code    gmv_mix   skus        mg       nmg    comp_mg         gpi  \\\n",
       "0       BHZ  37.445107  184.0  8.614564  3.492398   9.504738   99.273602   \n",
       "1       CWB  23.828168  170.0  9.194811  5.891820   6.548380  103.697914   \n",
       "2       SPO  54.885213  415.0  9.652923  6.782515   4.529234  105.876297   \n",
       "3       VCP  37.923383  243.0  9.378060  6.025572  13.577839   95.478007   \n",
       "\n",
       "          npi  \n",
       "0   94.320159  \n",
       "1  100.451990  \n",
       "2  102.693496  \n",
       "3   92.148891  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to apply the custom aggregation\n",
    "def custom_ventas(group, column):\n",
    "    return (100.00 * group[column] * group['gmv_mix']).sum()/group['gmv_mix'].sum()\n",
    "merge_df2 = df_atacado.dropna(how='any')\n",
    "# Group by 'city' and 'year_week', aggregate multiple columns with custom aggregation\n",
    "df_final_atacado = merge_df2.groupby(['site_code']).apply(lambda group: pd.Series({\n",
    "    'gmv_mix': 100.00*group['gmv_mix'].sum(),  # Compute sum of gmv_mix directly\n",
    "    'skus': group['source_id'].nunique(),\n",
    "    'mg': custom_ventas(group, 'mg'),\n",
    "    'nmg': custom_ventas(group, 'nmg'),\n",
    "    'comp_mg': custom_ventas(group, 'comp_mg'),\n",
    "    'gpi': custom_ventas(group, 'gpi'),\n",
    "    'npi': custom_ventas(group, 'npi')\n",
    "})).reset_index()\n",
    "print('INFOPRICE -ATACADAO INFO:')\n",
    "df_final_atacado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
