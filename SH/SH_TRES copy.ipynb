{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "    #Numeric Python\n",
    "import numpy as np\n",
    "    #Pandas (dataframes)\n",
    "import pandas as pd\n",
    "    #datetime for fate manipulation\n",
    "from datetime import date, datetime, timedelta  \n",
    "    #Regex for advanced string matching\n",
    "import re\n",
    "    #for time related stuff\n",
    "import time\n",
    "    #json library\n",
    "import json\n",
    "    #Analyst tools\n",
    "import sys\n",
    "sys.path.append('~')\n",
    "from analysts_tools.growth import *\n",
    "    #Procurement tools\n",
    "from analystcommunity.read_connection_data_warehouse import run_read_dwd_query\n",
    "from procurement_lib import send_slack_notification\n",
    "from procurement_lib import redash\n",
    "from analysts_tools.redash_methods import *\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "frida_products = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",118629,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH\n",
    "info AS (\n",
    "SELECT \n",
    "    MAX(fbi.dim_date) AS dim_date, \n",
    "    year_month_char,\n",
    "    dim_stock_unit \n",
    "FROM dpr_cross_business.fact_cross_business_insights fbi\n",
    "INNER JOIN dpr_shared.dim_date d ON d.date_id = fbi.dim_date\n",
    "WHERE margin_mtd <> 0\n",
    " AND full_date >= DATE_TRUNC('month', date(getdate()) - interval '0 month')\n",
    "GROUP BY 2,3\n",
    ")\n",
    "\n",
    "SELECT DISTINCT\n",
    "    s.identifier_value AS region,\n",
    "    su.sku,\n",
    "    su.card_id,\n",
    "    i.year_month_char AS month,\n",
    "    fbi.margin_mtd AS margin\n",
    "FROM dpr_cross_business.fact_cross_business_insights fbi\n",
    "INNER JOIN dpr_shared.dim_stock_unit su ON su.stock_unit_id = fbi.dim_stock_unit\n",
    "INNER JOIN dpr_shared.dim_site s ON s.site_id = fbi.dim_site\n",
    "INNER JOIN info i ON i.dim_date = fbi.dim_date AND i.dim_stock_unit = fbi.dim_stock_unit\n",
    "\"\"\"\n",
    "df_margin = run_read_dwd_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "df_hooks = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",108977,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//---------------------------------------------------------------------------------------------------------------------------\n",
    "#// Parametros\n",
    "city = 'VCP'\n",
    "    \n",
    "#year-month-day\n",
    "todays_date = datetime.datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_customers(city, recency_day_low=7, recency_day_top=30,  kam=100, graduate=100, msgt=('ALL'), sgt=('ALL')):\n",
    "    \"\"\"\n",
    "    This function filters the customers that have completed the specified criteria:\n",
    "    city: The city that the customer has been registered -> i.e 'BOG'\n",
    "    recency_day: The limit of days that the customer has completed an order -> 30 means 30 days or less\n",
    "    kam: If the customer is a KAM or No -> {100: ALL, 1: True, 0: False}\n",
    "    graduate: If the customer is GRADUATED or No -> {100: ALL, 1: True, 0: False}\n",
    "    msgt: The microsegment of the customer, this is different based on the city\n",
    "        - If you want to bring all should put as a tuple ('ALL')\n",
    "        - If you want to bring one msgt then i.e ('Fonda')\n",
    "        - If you want to bring more than one msgt then i.e ('Fonda','Corrientazo')\n",
    "    sgt: The segment of the customer\n",
    "        - If you want to bring all should put as a tuple ('ALL')\n",
    "        - If you want to bring one msgt then i.e ('Restaurante')\n",
    "        - If you want to bring more than one msgt then i.e ('Comercio','Restaurante')\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from analystcommunity.read_connection_data_warehouse import run_read_dwd_query\n",
    "\n",
    "    if isinstance(msgt, str):\n",
    "        msgt = (msgt,'a')  # Convert the string to a tuple with a single element\n",
    "    if isinstance(sgt, str):\n",
    "        sgt = (sgt,'a')  # Convert the string to a tuple with a single element\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        source_id AS customer_id,\n",
    "        is_kam_audited,\n",
    "        birthday,\n",
    "        last_order_date,\n",
    "        recency_days,\n",
    "        registered_city AS region,\n",
    "        salesperson_mail,\n",
    "        microsegment_name AS microsegment,\n",
    "        business_type AS segment,\n",
    "        is_graduated\n",
    "    FROM dpr_customer.obt_customer\n",
    "\n",
    "    WHERE recency_days <= {days}\n",
    "    AND recency_days >= {days2}\n",
    "    ----------------------------------\n",
    "    ----------------------------------\n",
    "    AND \n",
    "    CASE\n",
    "    WHEN '{city}' = 'ALL' THEN 1=1\n",
    "    ELSE registered_city = '{city}'\n",
    "    END\n",
    "    ----------------------------------\n",
    "    ----------------------------------\n",
    "    AND\n",
    "    CASE\n",
    "    WHEN {is_kam} = 100 THEN 1=1\n",
    "    ELSE is_kam_audited = {is_kam}\n",
    "    END\n",
    "    ----------------------------------\n",
    "    ----------------------------------\n",
    "    AND\n",
    "    CASE\n",
    "    WHEN {graduated} = 100 THEN 1=1\n",
    "    ELSE is_graduated = {graduated}\n",
    "    END\n",
    "    ----------------------------------\n",
    "    ----------------------------------\n",
    "    AND \n",
    "    CASE\n",
    "    WHEN 'ALL' IN {microsegment} THEN 1=1\n",
    "    ELSE microsegment_name IN {microsegment}\n",
    "    END\n",
    "    ----------------------------------\n",
    "    ----------------------------------\n",
    "    AND\n",
    "    CASE\n",
    "    WHEN 'ALL' IN {segment} THEN 1=1\n",
    "    ELSE business_type IN {segment}\n",
    "    END\n",
    "    \"\"\".format(days=recency_day_top,days2=recency_day_low,city=city,is_kam=kam,graduated=graduate,microsegment=msgt,segment=sgt)\n",
    "\n",
    "    return run_read_dwd_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_sells(city, sells_days_back_start=30, days_end=-1, customer=None):    \n",
    "    \"\"\"\n",
    "    This returns a df with the information of the whole sells order by order based on the restrictions\n",
    "    city: The city that the customer has been registered -> i.e 'BOG'\n",
    "    sells_days_back_start: Since when we want to see the orders information\n",
    "    days_end: Until when we want to see the orders information\n",
    "    \"\"\"    \n",
    "    import pandas as pd\n",
    "    from analystcommunity.read_connection_data_warehouse import run_read_dwd_query\n",
    "    import time\n",
    "    import datetime\n",
    "    \n",
    "    sells_date_inicio = (datetime.datetime.today() - datetime.timedelta(days=sells_days_back_start)).strftime('%Y-%m-%d') #1 months\n",
    "    sells_date_fin = (datetime.datetime.today() - datetime.timedelta(days=days_end)).strftime('%Y-%m-%d') #1 months\n",
    "    \n",
    "    tasas = {'BOG': 3776,\n",
    "            'BAQ': 3776,\n",
    "            'MDE': 3776,\n",
    "            'CMX': 19.65,\n",
    "            'GDL': 19.65,\n",
    "            'PBC': 19.65,\n",
    "            'SPO': 4.75,\n",
    "            'BHZ': 4.75,\n",
    "            'CWB': 4.75,\n",
    "            'VCP': 4.75}\n",
    "\n",
    "    if not isinstance(customer, list):\n",
    "        raise TypeError(\"Customer parameter must be a list.\")\n",
    "    elif customer is None:    \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.identifier_value AS region_code,\n",
    "            DATE(fs.order_submitted_date) AS submit_date,\n",
    "            fs.order_close_date AS close_date,\n",
    "            fs.order_id,\n",
    "            dc.source_id AS customer_id,\n",
    "            cat.parent_description as category,\n",
    "            cat.description AS subcategory,\n",
    "            dp.card_id,\n",
    "            dp.source_id AS sku_id,\n",
    "            dp.card_description AS product_name,\n",
    "            fs.product_quantity_x_step_unit AS cant,\n",
    "            fs.gmv_pxq_local/{tasa_cambio} AS gmv_usd,\n",
    "            COALESCE(fsd.product_discount/{tasa_cambio},0) AS discount_applied,\n",
    "            fsd.adjustment_reason,\n",
    "            COALESCE(bo.source_id,NULL) AS offer_id\n",
    "            \n",
    "        FROM dpr_sales.fact_sales                   fs\n",
    "        INNER JOIN dpr_shared.dim_customer          dc  ON dc.customer_id = fs.dim_customer\n",
    "        INNER JOIN dpr_shared.dim_site              s   ON s.site_id = fs.dim_site\n",
    "        INNER JOIN dpr_shared.dim_product           dp  ON dp.product_id = fs.dim_product\n",
    "        INNER JOIN dpr_shared.dim_category          cat ON cat.category_id = dp.category_id\n",
    "        LEFT JOIN dpr_sales.fact_sales_discounts    fsd ON fs.order_item_id = fsd.order_item_id \n",
    "        LEFT JOIN dpr_sales.dim_offer               bo  ON bo.offer_id = fsd.dim_offer     \n",
    "\n",
    "        WHERE \n",
    "            fs.gmv_enabled = TRUE\n",
    "            AND fulfillment_order_status NOT IN ('CANCELLED', 'ARCHIVED','No value')\n",
    "            AND fs.fb_order_status_id  IN (1,6,7,8)\n",
    "            AND fs.is_deleted = FALSE\n",
    "            AND fs.dim_status = 1\n",
    "            AND dp.is_slot = 'false'\n",
    "            --AND fsd.is_enabled = true\n",
    "            AND s.identifier_value = '{ciudad}'\n",
    "            AND DATE(fs.order_submitted_date) between '{Fecha_start}' AND '{Fecha_end}'\n",
    "    \"\"\".format(tasa_cambio = tasas[city], ciudad = city, Fecha_start = sells_date_inicio, Fecha_end = sells_date_fin)\n",
    "    else:\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.identifier_value AS region_code,\n",
    "            DATE(fs.order_submitted_date) AS submit_date,\n",
    "            fs.order_close_date AS close_date,\n",
    "            fs.order_id,\n",
    "            dc.source_id AS customer_id,\n",
    "            cat.parent_description as category,\n",
    "            cat.description AS subcategory,\n",
    "            dp.card_id,\n",
    "            dp.source_id AS sku_id,\n",
    "            dp.card_description AS product_name,\n",
    "            fs.product_quantity_x_step_unit AS cant,\n",
    "            fs.gmv_pxq_local/{tasa_cambio} AS gmv_usd,\n",
    "            COALESCE(fsd.product_discount/{tasa_cambio},0) AS discount_applied,\n",
    "            fsd.adjustment_reason,\n",
    "            COALESCE(bo.source_id,NULL) AS offer_id\n",
    "            \n",
    "        FROM dpr_sales.fact_sales                   fs\n",
    "        INNER JOIN dpr_shared.dim_customer          dc  ON dc.customer_id = fs.dim_customer\n",
    "        INNER JOIN dpr_shared.dim_site              s   ON s.site_id = fs.dim_site\n",
    "        INNER JOIN dpr_shared.dim_product           dp  ON dp.product_id = fs.dim_product\n",
    "        INNER JOIN dpr_shared.dim_category          cat ON cat.category_id = dp.category_id\n",
    "        LEFT JOIN dpr_sales.fact_sales_discounts    fsd ON fs.order_item_id = fsd.order_item_id \n",
    "        LEFT JOIN dpr_sales.dim_offer               bo  ON bo.offer_id = fsd.dim_offer     \n",
    "\n",
    "        WHERE \n",
    "            fs.gmv_enabled = TRUE\n",
    "            AND fulfillment_order_status NOT IN ('CANCELLED', 'ARCHIVED','No value')\n",
    "            AND fs.fb_order_status_id  IN (1,6,7,8)\n",
    "            AND fs.is_deleted = FALSE\n",
    "            AND fs.dim_status = 1\n",
    "            AND dp.is_slot = 'false'\n",
    "            --AND fsd.is_enabled = true\n",
    "            AND s.identifier_value = '{ciudad}'\n",
    "            AND DATE(fs.order_submitted_date) between '{Fecha_start}' AND '{Fecha_end}'\n",
    "            AND dc.source_id IN {clientes}\n",
    "    \"\"\".format(tasa_cambio = tasas[city], ciudad = city, Fecha_start = sells_date_inicio, Fecha_end = sells_date_fin,clientes=tuple(set(customer)))   \n",
    "    return run_read_dwd_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ('ALL') #the microsegments you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the clients that i want\n",
    "df_customers = filter_customers(city,7,30,100,100,group,('Restaurante'))#.customer_id.unique() #,'Taquería','Comida Rápida','Panadería/Pastelería'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_customers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading COSTUMERS INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ventas = info_sells(city, sells_days_back_start=60, days_end=-1, customer=df_customers.customer_id.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ventas_IQ = data_ventas.groupby(by=['region_code','customer_id']).agg({\"gmv_usd\":np.sum, \"order_id\":pd.Series.nunique}).reset_index()\n",
    "data_ventas_IQ[\"AOV\"] = data_ventas.gmv_usd/data_ventas.order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "def create_groups(offer):\n",
    "    \n",
    "    customers = offer.customer_id.unique()\n",
    "    print(\"Total length: \", len(customers))\n",
    "    customer_control, customer_test = train_test_split(customers, test_size = 0.85)\n",
    "    \n",
    "    alpha=0.01\n",
    "    aux=0\n",
    "    while abs(1-(offer[offer.customer_id.isin(customer_control)]['AOV'].mean()/offer[offer.customer_id.isin(customer_test)]['AOV'].mean())) > alpha:\n",
    "        customer_control, customer_test = train_test_split(customers, test_size = 0.85)\n",
    "        \n",
    "        aux+=1\n",
    "        if aux == 1000:\n",
    "            alpha+=0.01\n",
    "            aux=0\n",
    "        \n",
    "    return customer_control.tolist(), customer_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we should complete our data for each SH, important if we want to submit a subcategory SH offer, in SKUS we should put the skus into a list as this [[1,2,3]]\"\"\"\n",
    "card_id = [325412,325413]\n",
    "max_uses = [30,30]\n",
    "max_orders = [2,2]\n",
    "discount = [8,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length:  2839\n"
     ]
    }
   ],
   "source": [
    "offer_name = []\n",
    "global_segment_list = [] #//for procesing\n",
    "hooks = []\n",
    "\n",
    "control, test = create_groups(data_ventas_IQ)\n",
    "\n",
    "for sku in card_id:\n",
    "    name = frida_products.loc[frida_products.id_tarjeta == sku,'card_name'].values[0]\n",
    "    offer_name.append(\"SH_CUORTO_\"+todays_date+\"_\"+city+\"_\"+name)\n",
    "    \n",
    "\n",
    "    d = {'name':\"SH_CUORTO_\"+todays_date+\"_\"+city+\"_\"+name, 'customersIds': list(test),\"expiresAt\": (datetime.datetime.today() + datetime.timedelta(days=(1))).strftime('%Y-%m-%d')}\n",
    "    e = {'name':\"SH_CUORTO_\"+todays_date+\"_\"+city+\"_\"+name+\"_CONTROL\", 'customersIds': list(control),\"expiresAt\": (datetime.datetime.today() + datetime.timedelta(days=(1))).strftime('%Y-%m-%d')}\n",
    "    \n",
    "    global_segment_list.append(d)\n",
    "    global_segment_list.append(e)\n",
    "    \n",
    "    if df_hooks.loc[df_hooks.addl_product_id == sku].value_discount.max():\n",
    "        hooks.append(df_hooks.loc[df_hooks.addl_product_id == sku].value_discount.max())\n",
    "    else:\n",
    "        hooks.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SH_CUORTO_2023-11-16_VCP_Óleo de Soja Vitaliv 900ml_HDCT_0.75', 'SH_CUORTO_2023-11-16_VCP_Leite Integral Shefa 1L_HDCT_0']\n"
     ]
    }
   ],
   "source": [
    "offer_name2 = []\n",
    "for i, name in enumerate(offer_name):\n",
    "    # Retrieve rows that match the condition\n",
    "    matching_rows = df_hooks.loc[df_hooks.addl_product_id == card_id[i], [\"value_discount\"]]\n",
    "    \n",
    "    # Check if matching_rows is empty\n",
    "    if matching_rows.empty:\n",
    "        default_value = 0\n",
    "    else:\n",
    "        # Get the unique discount value from matching rows\n",
    "        discount_value = matching_rows[\"value_discount\"].unique()[0]\n",
    "        \n",
    "        # Calculate the updated value\n",
    "        default_value = round(discount_value / discount[i], 2)\n",
    "    \n",
    "    # Update offer_name[i] with the calculated value\n",
    "    offer_name2.append(offer_name[i] + \"_HDCT_\" + str(default_value))    \n",
    "print(offer_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SH_CUORTO_2023-11-16_VCP_Óleo de Soja Vitaliv 900ml', 'SH_CUORTO_2023-11-16_VCP_Leite Integral Shefa 1L']\n",
      "['SH_CUORTO_2023-11-16_VCP_Óleo de Soja Vitaliv 900ml_HDCT_0.75', 'SH_CUORTO_2023-11-16_VCP_Leite Integral Shefa 1L_HDCT_0']\n"
     ]
    }
   ],
   "source": [
    "print(offer_name)\n",
    "print(offer_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = {} \n",
    "csv_file['offer_name'] = offer_name2\n",
    "csv_file['offer_description'] = None\n",
    "csv_file['discount'] = discount\n",
    "csv_file['automatically_consider_offer'] = \"true\"\n",
    "csv_file['start_date'] = (datetime.datetime.today() + datetime.timedelta(days=0)).strftime('%d-%m-%Y')\n",
    "csv_file['end_date'] = (datetime.datetime.today() + datetime.timedelta(days=(1))).strftime('%d-%m-%Y')\n",
    "csv_file['max_uses_per_order'] = max_uses\n",
    "csv_file['max_uses_per_customer'] = max_orders\n",
    "csv_file['customer_segment_id'] = [1]*len(offer_name) #[None]\n",
    "csv_file['sku_id'] = [frida_products.loc[frida_products.id_tarjeta == sku,\"skus\"].values[0] for sku in card_id]\n",
    "csv_file['segment_behaviour'] = 'INCLUDED'\n",
    "csv_file['offer_type'] = 'SUPER_DISCOUNT'\n",
    "csv_file['supplier_discount'] = 0\n",
    "\n",
    "global_offer_csv = pd.DataFrame(csv_file) #, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = f\"https://{city}.frubana.com/api/v1/segments/create?api-key=00_growth-team-zzz-qqq_001\"\n",
    "\n",
    "payload = json.dumps(global_segment_list)\n",
    "\n",
    "\n",
    "headers = {\n",
    "  'Cookie': 'AWSALB=WGKrKvA1CFOY0m92xSENGAseuE4LrcfQh9y8jK/loGBJdizNm+FvjOqUqVghxdfLkH6Jsa9sfWft2NELchGAP/LNZMXMYhrOE70qDnUuOHATpdJj1UZBMEUBSIN1; AWSALBCORS=WGKrKvA1CFOY0m92xSENGAseuE4LrcfQh9y8jK/loGBJdizNm+FvjOqUqVghxdfLkH6Jsa9sfWft2NELchGAP/LNZMXMYhrOE70qDnUuOHATpdJj1UZBMEUBSIN1; AWSALB=jLY02FPysvF1vTrKLhXbk3ibzmyiAqFJ1ezYVu5PjodkU2QmPHDpRJhb9CvOlOyQ1Ix0mJR1ig+eH9zwJ9i5EOtgsgx79NSROogQb2Ua6yLX/I3bJJ6xtcVO3puI; AWSALBCORS=jLY02FPysvF1vTrKLhXbk3ibzmyiAqFJ1ezYVu5PjodkU2QmPHDpRJhb9CvOlOyQ1Ix0mJR1ig+eH9zwJ9i5EOtgsgx79NSROogQb2Ua6yLX/I3bJJ6xtcVO3puI',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgt = [(int(x[:6]),x[7:]) for x in list(map(str.strip, response.text[32:].strip('][').replace('\"', '').split(',')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(501504, 'SH_CUORTO_2023-11-16_VCP_Óleo de Soja Vitaliv 900ml'),\n",
       " (501502, 'SH_CUORTO_2023-11-16_VCP_Óleo de Soja Vitaliv 900ml_CONTROL'),\n",
       " (501505, 'SH_CUORTO_2023-11-16_VCP_Leite Integral Shefa 1L'),\n",
       " (501503, 'SH_CUORTO_2023-11-16_VCP_Leite Integral Shefa 1L_CONTROL')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,name in enumerate(global_offer_csv.offer_name):\n",
    "    for j,z in sgt:\n",
    "        if z==offer_name[i]:\n",
    "            global_offer_csv.loc[[i], ('customer_segment_id')] = j\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_name</th>\n",
       "      <th>offer_description</th>\n",
       "      <th>discount</th>\n",
       "      <th>automatically_consider_offer</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>max_uses_per_order</th>\n",
       "      <th>max_uses_per_customer</th>\n",
       "      <th>customer_segment_id</th>\n",
       "      <th>sku_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SH_CUORTO_2023-11-16_VCP_Óleo de Soja Vitaliv ...</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>true</td>\n",
       "      <td>16-11-2023</td>\n",
       "      <td>17-11-2023</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>501504</td>\n",
       "      <td>428399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SH_CUORTO_2023-11-16_VCP_Leite Integral Shefa ...</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>true</td>\n",
       "      <td>16-11-2023</td>\n",
       "      <td>17-11-2023</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>501505</td>\n",
       "      <td>428402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          offer_name offer_description  \\\n",
       "0  SH_CUORTO_2023-11-16_VCP_Óleo de Soja Vitaliv ...              None   \n",
       "1  SH_CUORTO_2023-11-16_VCP_Leite Integral Shefa ...              None   \n",
       "\n",
       "   discount automatically_consider_offer  start_date    end_date  \\\n",
       "0         8                         true  16-11-2023  17-11-2023   \n",
       "1         5                         true  16-11-2023  17-11-2023   \n",
       "\n",
       "   max_uses_per_order  max_uses_per_customer  customer_segment_id  sku_id  \n",
       "0                  30                      2               501504  428399  \n",
       "1                  30                      2               501505  428402  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_offer_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"group\" column based on customer_id\n",
    "df_customers['group'] = 'none'  # Initialize the group column with a default value\n",
    "\n",
    "# Mark customers in the control list as 'control' in the 'group' column\n",
    "df_customers.loc[df_customers['customer_id'].isin(control), 'group'] = 'control'\n",
    "\n",
    "# Mark customers in the test list as 'test' in the 'group' column\n",
    "df_customers.loc[df_customers['customer_id'].isin(test), 'group'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//--------------------------------------------\n",
    "#//Exporting single file data\n",
    "global_offer_csv.to_csv(f'{city}/{todays_date}_SH_CUORTO_{city}_OFFER_csv.csv', index = False)\n",
    "df_customers.to_csv(f'{city}/{todays_date}_SH_CUORTO_INFO_CUSTOMERS.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "624741679a3ae5d99cecf49b8df5d516a7a937e6e7328e129d1fa121c8592e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
