{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//----------------------------\n",
    "#//LIBRARIES\n",
    "    #Math\n",
    "import math\n",
    "    #Numeric Python\n",
    "import numpy as np\n",
    "    #Pandas (dataframes)\n",
    "import pandas as pd\n",
    "    #datetime for fate manipulation\n",
    "from datetime import date, datetime, timedelta  \n",
    "    #Regex for advanced string matching\n",
    "import re\n",
    "    #for time related stuff\n",
    "import time\n",
    "    #json library\n",
    "import json\n",
    "    #Analyst tools\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from analysts_tools.growth import *\n",
    "    #Procurement tools\n",
    "from procurement_lib import send_slack_notification\n",
    "from procurement_lib import redash\n",
    "from analysts_tools.redash_methods import *\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargue de Queries y parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'VCP'\n",
    "customer_date_desde = (datetime.datetime.today() - datetime.timedelta(days=200))#.strftime('%Y-%m-%d') #1 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "margenes = pd.read_csv(\"Margenes_neto.csv\")\n",
    "retention = pd.read_csv(\"retention_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_aux =  retention.copy()\n",
    "\n",
    "for i,ret in enumerate(retention_aux.values):\n",
    "    retention_aux.iloc[i,2:] = [(1-(j-ret[-1])/100) if j-ret[-1] >= 0 else 1 for j in ret[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "clear_buyers = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",138674,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "\n",
    "c.assignee_ref_id AS \"Owner\",\n",
    "cm.member_ref_id AS \"customer_id\",\n",
    "--cm.status AS \"Estado de la asignacion\",\n",
    "--c.type as \"Tipo de asociacion\",\n",
    "--c.flow_type AS \"Tipo de carga\",\n",
    "z.value AS \"Ciudad\"\n",
    "--p.since AS \"Semana\"\n",
    "\n",
    "FROM postgres_growth_offline.\"growth_clustering.clusters\"               c\n",
    "INNER JOIN postgres_growth_offline.\"growth_clustering.cluster_members\"  cm  ON cm.cluster_id = c.id\n",
    "INNER JOIN postgres_growth_offline.\"growth_clustering.periods\"          p   ON p.id = c.period_id\n",
    "INNER JOIN postgres_growth_offline.\"growth_clustering.zones\"            z   ON z.id = c.zone_id\n",
    "\n",
    "where p.since = DATE_TRUNC('week', date(getdate()) - interval '0 week')\n",
    "and z.value in ('BOG','BAQ','MDE','CMX','SPO','BHZ','CWB','VCP')\n",
    "and c.type = 'FARMER_OFFLINE'\n",
    "and c.status = 'ACTIVE'\n",
    "and c.enabled = 'true'\n",
    "\"\"\"\n",
    "data_farming = read_connection_data_warehouse.runQuery(query)\n",
    "data_farming[[\"customer_id\"]] = data_farming[[\"customer_id\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "-- 93058\n",
    "-- Se toma como base el query 2718\n",
    "WITH \n",
    "ful AS (\n",
    "\n",
    "SELECT DISTINCT\n",
    "    bo.order_id,\n",
    "    bo.submit_date\n",
    "    \n",
    "FROM postgres_broadleaf_federate.\"broadleaf.blc_order\" bo\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_fulfillment_group\" bfg        ON bfg.order_id = bo.order_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_fulfillment_order\" bfo        ON bfo.fulfillment_group_id = bfg.fulfillment_group_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.fb_fulfillment_group\" ffg         ON ffg.fulfillment_group_id = bfg.fulfillment_group_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.fb_order\" fo                      ON fo.order_id = bo.order_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_order_payment\" bop            ON bop.order_id = bo.order_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_site\" s                       ON s.site_id = bo.site_disc\n",
    "LEFT JOIN  postgres_broadleaf_federate.\"broadleaf.fb_order_type\" fot                ON fot.fb_order_type_id=fo.fb_order_type_id\n",
    "LEFT JOIN  postgres_broadleaf_federate.\"broadleaf.blc_order_adjustment\" ba          ON ba.order_id = bo.order_id\n",
    "\n",
    "WHERE fo.fb_order_status_id IN (1,6,7,8)\n",
    "    --AND extract(year from bo.submit_date::date) = 2021\n",
    "    --AND extract(month from bo.submit_date::date) = 6--2021\n",
    "    AND bo.order_status = 'SUBMITTED'\n",
    "    AND bfo.status NOT IN ('ARCHIVED','CANCELLED')\n",
    "    AND bop.archived = 'N'\n",
    "    AND (fot.name IS NULL OR fot.name <> 'REFUND')\n",
    "    AND s.site_identifier_value = '{city}' --NOT IN ('MTY','PBC','GDL')\n",
    "    AND bo.customer_id IN {clientes}\n",
    "GROUP BY bo.order_id, bo.submit_date\n",
    ")--,\n",
    "\n",
    "--more AS (\n",
    "SELECT DISTINCT\n",
    "    s.site_identifier_value AS city,\n",
    "    bo.customer_id,\n",
    "    DATE(bo.submit_date) AS submit_date,\n",
    "    bo.order_id,\n",
    "    bs.addl_product_id AS padre_sku_id,\n",
    "    CASE\n",
    "    WHEN bcat2.name = 'Abarrotes & Despensa' THEN 'Abarrotes'\n",
    "    ELSE bcat2.name END AS cat,\n",
    "    --bcat.name AS subcat,\n",
    "    --bs2.name,\n",
    "    CASE \n",
    "        WHEN s.site_identifier_value = 'CMX' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/19.65\n",
    "        WHEN s.site_identifier_value = 'GDL' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/19.65\n",
    "        WHEN s.site_identifier_value = 'PBC' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/19.65\n",
    "        WHEN s.site_identifier_value = 'MTY' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/19.65\n",
    "        WHEN s.site_identifier_value = 'SPO' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/4.75\n",
    "        WHEN s.site_identifier_value = 'BHZ' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/4.75\n",
    "        WHEN s.site_identifier_value = 'CWB' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/4.75\n",
    "        WHEN s.site_identifier_value = 'VCP' then (boi.quantity * foi.step_unit * boi.sale_price)*1.0/4.75\n",
    "    ELSE (boi.quantity * foi.step_unit * boi.sale_price)*1.0/3776 END AS gmv_usd,    \n",
    "    -- CASE \n",
    "    --     WHEN s.site_identifier_value = 'CMX' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/19.65\n",
    "    --     WHEN s.site_identifier_value = 'GDL' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/19.65\n",
    "    --     WHEN s.site_identifier_value = 'PBC' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/19.65\n",
    "    --     WHEN s.site_identifier_value = 'MTY' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/19.65\n",
    "    --     WHEN s.site_identifier_value = 'SPO' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/4.75\n",
    "    --     WHEN s.site_identifier_value = 'BHZ' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/4.75\n",
    "    --     WHEN s.site_identifier_value = 'CWB' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/4.75\n",
    "    --     WHEN s.site_identifier_value = 'VCP' then (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/4.75\n",
    "    -- ELSE (boida.adjustment_value * boipd.quantity * foi.step_unit)*1.0/3776 END AS discount_usd,\n",
    "    (boi.quantity*foi.step_unit) AS cant\n",
    "\n",
    "FROM postgres_broadleaf_federate.\"broadleaf.blc_order\" bo\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_site\"                     s       ON s.site_id = bo.site_disc\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_order_item\"               boi     ON boi.order_id=bo.order_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.fb_order_item\"                foi     ON boi.order_item_id= foi.order_item_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.fb_order\"                     fo      ON fo.order_id = bo.order_id\n",
    "INNER JOIN ful                                                                          ON ful.order_id = bo.order_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_discrete_order_item\"      bdoi    ON bdoi.order_item_id = boi.order_item_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_sku\"                      bs      ON bs.sku_id = bdoi.sku_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_product\"                  bp      ON bs.addl_product_id = bp.product_id\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_sku\"                      bs2     ON bs2.sku_id = bp.default_sku_id --Conectar la tarjeta con el sku que guarda la info\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_category\"                 bcat    ON bcat.category_id = bp.default_category_id \n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_category_xref\"            bcx     ON bcx.sub_category_id = bp.default_category_id AND bcx.archived='N' AND bcx.sndbx_tier is NULL\n",
    "INNER JOIN postgres_broadleaf_federate.\"broadleaf.blc_category\"                 bcat2   ON bcx.category_id = bcat2.category_id\n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_order_item_price_dtl\"      boipd   ON boipd.order_item_id=boi.order_item_id\n",
    "LEFT JOIN postgres_broadleaf_federate.\"broadleaf.blc_order_item_dtl_adj\"        boida   ON boida.order_item_price_dtl_id=boipd.order_item_price_dtl_id\n",
    "\n",
    "WHERE fb_order_status_id IN (1,6,7,8)\n",
    "    AND bo.order_status = 'SUBMITTED'\n",
    "   -- FIX SUPER DESCUENTOS\n",
    "    AND bcat2.category_id not in ('110873','-1000','100768','100765','100815') --ids de super descuentos en cada país\n",
    "    AND bcat.name <> 'Oferton Frubana' AND bcat2.name <> 'Oferton Frubana'\n",
    "\"\"\".format(clientes=tuple(set(clear_buyers[clear_buyers.registered_city == city].customer_id.unique())), city = city)\n",
    "\n",
    "data_ventas_aux = read_connection_data_warehouse.runQuery(query)\n",
    "data_ventas_aux[[\"gmv_usd\", \"cant\"]] = data_ventas_aux[[\"gmv_usd\", \"cant\"]].astype(float)\n",
    "data_ventas_aux['submit_date'] = pd.to_datetime(data_ventas_aux['submit_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = data_ventas_aux.groupby(by=['customer_id']).agg({'submit_date':np.max}).reset_index()\n",
    "df = data_ventas_aux[data_ventas_aux.customer_id.isin(check_df[check_df.submit_date >= customer_date_desde].customer_id.unique())].groupby(by=['city', 'customer_id', 'submit_date','cat']).agg({'gmv_usd':'sum','cant':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ENAE = data_ventas_aux[['city','customer_id','submit_date','order_id', 'gmv_usd']].groupby(by=['city','customer_id','submit_date','order_id'])['gmv_usd'].sum().reset_index()\n",
    "#df_ENAE.to_csv(\"info_ENAE.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacion de df con info by cat by client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('submit_date',ignore_index=True)\n",
    "\n",
    "#fix for id problems and taking into account only dates\n",
    "df['order_id']= df.submit_date.apply(lambda x:x.toordinal()) \n",
    "\n",
    "#Days of difference between orders for customer and for cat\n",
    "df['days_bet'] = (df.submit_date -df.groupby('customer_id').submit_date.transform('min')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This calculate in res the difference between consecutive orders and with the agg we calculate all metrics\n",
    "df['res'] = df.groupby(by=['customer_id', 'cat'])['days_bet'].diff()\n",
    "df_grouped = df.groupby(by=['city', 'customer_id', 'cat']).agg({'res': [np.min, np.max, np.mean, np.median, np.std],\n",
    "                                                                    'order_id': [lambda x: x.nunique()], \n",
    "                                                                    'gmv_usd': [np.mean],\n",
    "                                                                    'cant': [np.mean],\n",
    "                                                                    'submit_date': [np.max, lambda x: (x.max()-x.min()).days, lambda x: (datetime.datetime.today() - x.max()).days, np.min]\n",
    "                                                                    }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we define everything in a df2 for further processing\n",
    "df2 = df_grouped.copy()\n",
    "\n",
    "df2.columns = ['city', 'customer_id', 'cat', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
    "               'num_orders', 'aov_cat_usd', 'avg_cant_cat', 'last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order','first_order_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_month(d1, d2):\n",
    "    return (d1.year - d2.year) * 12 + d1.month - d2.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_metrics_2(cat):\n",
    "    df_cat = df2[df2.cat == cat].copy()\n",
    "    \n",
    "    df_cat['adjust_std'] = pd.qcut(df_cat.stdev_diff_days, 10, labels=[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])\n",
    "    df_cat[[\"adjust_std\"]] = df_cat[[\"adjust_std\"]].astype(float)\n",
    "    \n",
    "    df_cat['adjust_cohort'] = [1 if ((x[13]) - (x[5]+x[7]) <= 0) else  \n",
    "                 1/(((x[13]) - x[5])/x[7]) if x[7] != 0 else\n",
    "                 1/(((x[13]) - x[5])/np.round(1+(x[5]*0.7)))\n",
    "                 for x in df_cat.values]\n",
    "    \n",
    "    df_cat[\"margen\"] = [margenes[(margenes.category == x[2]) & (margenes.region_code == x[0])][\"net_margin\"].unique()[0]/100 for x in df_cat.values]\n",
    "    #mirar aca\n",
    "    df_cat['adjust_retention'] = [1 if diff_month(x[11],x[14])+1 >= 10 else \n",
    "                                  retention_aux[(retention_aux.category == x[2]) & (retention_aux.region_code == x[0])][str(diff_month(x[11],x[14])+1)].unique()[0] for x in df_cat.values]\n",
    "    \n",
    "    df_cat['median_diff_days_adjusted'] = 365/df_cat.median_diff_days\n",
    "    \n",
    "    df_cat[\"churned\"] = [0 if ((x[13]) - (x[5]+x[7]*2) <= 0) else 1 for x in df_cat.values]\n",
    "    \n",
    "    df_cat[['avg_diff_days','stdev_diff_days']] = df_cat[['avg_diff_days','stdev_diff_days']].fillna(0)\n",
    "\n",
    "    df_cat['churned_date'] = [(x[11] + datetime.timedelta(days=int(x[5]+x[7]*2))).strftime('%Y-%m-%d') for x in df_cat.values] #1 months\n",
    "    \n",
    "    df_cat[\"CLTV\"] = df_cat.median_diff_days_adjusted * df_cat.margen * df_cat.aov_cat_usd * df_cat.adjust_retention * df_cat.adjust_std * df_cat.adjust_cohort\n",
    "    df_cat[\"CLTV_sin_margen\"] = df_cat.median_diff_days_adjusted * df_cat.aov_cat_usd * df_cat.adjust_retention * df_cat.adjust_std * df_cat.adjust_cohort\n",
    "    df_cat[\"CLTV_sin_churn\"] = df_cat.median_diff_days_adjusted * df_cat.margen * df_cat.aov_cat_usd * df_cat.adjust_retention * df_cat.adjust_std\n",
    "    \n",
    "    df_cat['cash_margin'] = df_cat.aov_cat_usd * df_cat.margen\n",
    "\n",
    "    return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['cat'] = df2['cat'].str.replace('Abarrotes & Despensa', 'Abarrotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descartáveis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Descartáveis\n",
      "Frutas e Verduras\n",
      "Done Frutas e Verduras\n",
      "Laticínios e Ovos\n",
      "Done Laticínios e Ovos\n",
      "Limpeza e Higiene\n",
      "Done Limpeza e Higiene\n",
      "Mercearia\n",
      "Done Mercearia\n",
      "Bebidas\n",
      "Done Bebidas\n",
      "Carnes, Aves e Peixes\n",
      "Done Carnes, Aves e Peixes\n",
      "Congelados\n",
      "Done Congelados\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "\n",
    "for cat in df2.cat.unique():\n",
    "   print(cat)\n",
    "   if cat not in ('Mesa & Cocina','Insumos Internos Cat','Despensa'):\n",
    "      df3 = df3.append(cat_metrics_2(cat))\n",
    "   print(f'Done {cat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cat</th>\n",
       "      <th>min_diff_days</th>\n",
       "      <th>max_diff_days</th>\n",
       "      <th>avg_diff_days</th>\n",
       "      <th>median_diff_days</th>\n",
       "      <th>stdev_diff_days</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>aov_cat_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>adjust_cohort</th>\n",
       "      <th>margen</th>\n",
       "      <th>adjust_retention</th>\n",
       "      <th>median_diff_days_adjusted</th>\n",
       "      <th>churned</th>\n",
       "      <th>churned_date</th>\n",
       "      <th>CLTV</th>\n",
       "      <th>CLTV_sin_margen</th>\n",
       "      <th>CLTV_sin_churn</th>\n",
       "      <th>cash_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VCP</td>\n",
       "      <td>54609840</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.694730</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.203451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VCP</td>\n",
       "      <td>135201529</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.562100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.941</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.648538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149306304</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>60.600000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>44.635188</td>\n",
       "      <td>6</td>\n",
       "      <td>28.615077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835865</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.186441</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>9.677198</td>\n",
       "      <td>44.390816</td>\n",
       "      <td>11.577466</td>\n",
       "      <td>6.238087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149313616</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.151570</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.997</td>\n",
       "      <td>2.644928</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149317776</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>12.614735</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.941</td>\n",
       "      <td>26.071429</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149318063</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.520000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.839623</td>\n",
       "      <td>26</td>\n",
       "      <td>2.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.000</td>\n",
       "      <td>28.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>13.641114</td>\n",
       "      <td>62.573915</td>\n",
       "      <td>13.641114</td>\n",
       "      <td>0.607310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149327686</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5.076835</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.941</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.106750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149350490</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.272727</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.023755</td>\n",
       "      <td>12</td>\n",
       "      <td>6.721221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.991</td>\n",
       "      <td>33.181818</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>1.986335</td>\n",
       "      <td>9.111630</td>\n",
       "      <td>38.545038</td>\n",
       "      <td>1.465226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149373205</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>61.439866</td>\n",
       "      <td>9</td>\n",
       "      <td>17.832740</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15.869565</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>12.338705</td>\n",
       "      <td>56.599566</td>\n",
       "      <td>12.338705</td>\n",
       "      <td>3.887537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>VCP</td>\n",
       "      <td>149399006</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>10.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>59.400000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>69.923530</td>\n",
       "      <td>6</td>\n",
       "      <td>32.143152</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.000</td>\n",
       "      <td>13.035714</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>9.134395</td>\n",
       "      <td>41.900894</td>\n",
       "      <td>9.134395</td>\n",
       "      <td>7.007207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  customer_id           cat  min_diff_days  max_diff_days  \\\n",
       "0   VCP     54609840  Descartáveis            NaN            NaN   \n",
       "11  VCP    135201529  Descartáveis           20.0           20.0   \n",
       "17  VCP    149306304  Descartáveis            5.0          111.0   \n",
       "24  VCP    149313616  Descartáveis          138.0          138.0   \n",
       "30  VCP    149317776  Descartáveis           14.0           14.0   \n",
       "36  VCP    149318063  Descartáveis            6.0           60.0   \n",
       "43  VCP    149327686  Descartáveis            4.0            4.0   \n",
       "49  VCP    149350490  Descartáveis            3.0           42.0   \n",
       "54  VCP    149373205  Descartáveis            5.0          191.0   \n",
       "61  VCP    149399006  Descartáveis           10.0          181.0   \n",
       "\n",
       "    avg_diff_days  median_diff_days  stdev_diff_days  num_orders  aov_cat_usd  \\\n",
       "0        0.000000               NaN         0.000000           1    14.694730   \n",
       "11      20.000000              20.0         0.000000           2     7.562100   \n",
       "17      60.600000              59.0        44.635188           6    28.615077   \n",
       "24     138.000000             138.0         0.000000           2     3.151570   \n",
       "30      14.000000              14.0         0.000000           2    12.614735   \n",
       "36      15.520000              13.0        11.839623          26     2.785825   \n",
       "43       4.000000               4.0         0.000000           2     5.076835   \n",
       "49      14.272727              11.0        13.023755          12     6.721221   \n",
       "54      45.000000              23.0        61.439866           9    17.832740   \n",
       "61      59.400000              28.0        69.923530           6    32.143152   \n",
       "\n",
       "    ...  adjust_cohort margen  adjust_retention  median_diff_days_adjusted  \\\n",
       "0   ...            NaN  0.218             0.941                        NaN   \n",
       "11  ...            NaN  0.218             0.941                  18.250000   \n",
       "17  ...       0.835865  0.218             1.000                   6.186441   \n",
       "24  ...            NaN  0.218             0.997                   2.644928   \n",
       "30  ...            NaN  0.218             0.941                  26.071429   \n",
       "36  ...       1.000000  0.218             1.000                  28.076923   \n",
       "43  ...            NaN  0.218             0.941                  91.250000   \n",
       "49  ...       0.051533  0.218             0.991                  33.181818   \n",
       "54  ...       1.000000  0.218             1.000                  15.869565   \n",
       "61  ...       1.000000  0.218             1.000                  13.035714   \n",
       "\n",
       "   churned  churned_date       CLTV  CLTV_sin_margen  CLTV_sin_churn  \\\n",
       "0        1    2023-01-12        NaN              NaN             NaN   \n",
       "11       1    2022-07-18        NaN              NaN             NaN   \n",
       "17       0    2023-08-01   9.677198        44.390816       11.577466   \n",
       "24       1    2023-03-05        NaN              NaN             NaN   \n",
       "30       1    2022-06-13        NaN              NaN             NaN   \n",
       "36       0    2023-07-10  13.641114        62.573915       13.641114   \n",
       "43       1    2022-05-17        NaN              NaN             NaN   \n",
       "49       1    2022-11-12   1.986335         9.111630       38.545038   \n",
       "54       0    2023-10-22  12.338705        56.599566       12.338705   \n",
       "61       0    2023-09-26   9.134395        41.900894        9.134395   \n",
       "\n",
       "    cash_margin  \n",
       "0      3.203451  \n",
       "11     1.648538  \n",
       "17     6.238087  \n",
       "24     0.687042  \n",
       "30     2.750012  \n",
       "36     0.607310  \n",
       "43     1.106750  \n",
       "49     1.465226  \n",
       "54     3.887537  \n",
       "61     7.007207  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aca empieza el analisis global by customer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, i group the df3 (the df with the whole info by cat to customer lvl)\n",
    "df_new3 = df3[['city','customer_id','aov_cat_usd','cash_margin','CLTV_sin_churn','churned']].groupby(by=['city','customer_id']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The processing data for customer level is made here\n",
    "\n",
    "df_new = df.groupby(by=['city','customer_id','order_id','submit_date']).sum().reset_index()\n",
    "\n",
    "df_new['days_bet'] = (df_new.submit_date -df_new.groupby('customer_id').submit_date.transform('min')).dt.days\n",
    "\n",
    "#This calculate in res the difference between consecutive orders and with the agg we calculate all metrics\n",
    "df_new['res'] = df_new.groupby(by=['customer_id'])['days_bet'].diff()\n",
    "df_grouped_2 = df_new.groupby(by=['city', 'customer_id']).agg({'res': [np.min, np.max, np.mean, np.median, np.std],\n",
    "                                                                    'order_id': [lambda x: x.nunique()], \n",
    "                                                                    'gmv_usd': [np.mean],\n",
    "                                                                    'cant': [np.mean],\n",
    "                                                                    'submit_date': [np.max, lambda x: (x.max()-x.min()).days, lambda x: (datetime.datetime.today() - x.max()).days, np.min]\n",
    "                                                                    }).droplevel(0, axis=\"columns\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we define everything in a df_new2 at level customer for further processing\n",
    "df_new2 = df_grouped_2.copy()\n",
    "\n",
    "df_new2.columns = ['city', 'customer_id', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
    "               'num_orders', 'aov_ALL_usd', 'ALL_avg_cant', 'last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order','first_order_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we calculate the next parameters and also integred with df_new3 where we can have the info grouped by customer about the category performance\n",
    "df_new2[\"churned_ALL\"] = [0 if ((x[12]) - (x[4]+x[6]*2) <= 0) else 1 for x in df_new2.values]\n",
    "\n",
    "df_new2['adjust_std'] = pd.qcut(df_new2.stdev_diff_days, 10, labels=[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])\n",
    "df_new2[[\"adjust_std\"]] = df_new2[[\"adjust_std\"]].astype(float)\n",
    "\n",
    "df_new2['adjust_retention'] = [1 if diff_month(x[10],x[13])+1 >= 10 else \n",
    "                                retention_aux[(retention_aux.region_code == x[0])][str(diff_month(x[10],x[13])+1)].max() for x in df_new2.values]\n",
    "\n",
    "df_new2['median_diff_days_adjusted'] = 365/df_new2.median_diff_days\n",
    "\n",
    "#this merge is to include the info for the total cash_margin, how many cats is churned and the total cat CLTV\n",
    "df_new2 = df_new2.merge(df_new3[['customer_id','cash_margin','CLTV_sin_churn','churned']], on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652743.0000702777 644055.1230137593\n"
     ]
    }
   ],
   "source": [
    "#We calculate now the CLTV taking into account the global behavior of the customer\n",
    "df_new2[\"ALL_CLTV_sin_churn\"] = df_new2.median_diff_days_adjusted * df_new2.adjust_retention * df_new2.adjust_std * df_new2.cash_margin / 2\n",
    "df_new2[['CLTV_sin_churn','ALL_CLTV_sin_churn']] = df_new2[['CLTV_sin_churn','ALL_CLTV_sin_churn']].fillna(0)\n",
    "\n",
    "#df_new2[\"CLTV\"] = df_new2.median_diff_days_adjusted * df_new2.margen * df_new2.aov_cat_usd * df_new2.adjust_retention * df_new2.adjust_std * df_new2.adjust_cohort\n",
    "#df_new2[\"CLTV_sin_margen\"] = df_new2.median_diff_days_adjusted * df_new2.aov_cat_usd * df_new2.adjust_retention * df_new2.adjust_std * df_new2.adjust_cohort\n",
    "\n",
    "#If the Total Cat CLTV is NA because it is so few orders for each category, we create a Adjust_CLTV to include the global or ALL_CLTV_sin_churn instead of the NULL value\n",
    "df_new2['Adjust_CLTV'] = [x[21] if x[19] == 0 else x[19] for x in df_new2.values]\n",
    "\n",
    "print(df_new2.Adjust_CLTV.sum(),df_new2.CLTV_sin_churn.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we calculate the ALL_churned_date based on the general behavior of the customer\n",
    "df_new2[['avg_diff_days','stdev_diff_days']] = df_new2[['avg_diff_days','stdev_diff_days']].fillna(0)\n",
    "df_new2['ALL_churned_date'] = [(x[10] + datetime.timedelta(days=int(x[4]+x[6]*2))).strftime('%Y-%m-%d') for x in df_new2.values] #1 months"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final processing of the file to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will merge the df_new2 with the clear_buyers in order to filter by restaurants and take away kams (also to include the microsegment)\n",
    "df_new2 = df_new2.merge(clear_buyers[clear_buyers.registered_city == city][['customer_id','business_type','microsegment_name','is_kam']], on='customer_id', how='left')\n",
    "df_new2_end = df_new2[(df_new2.is_kam == 0)].copy() #df_new2[(df_new2.business_type == 'Restaurante') & (df_new2.is_kam == 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is to calculate the cumulative sum to create the tiers further\n",
    "df_new2_end = df_new2_end.sort_values(['Adjust_CLTV'], ascending=[False])\n",
    "df_new2_end['cumsum'] = df_new2_end.groupby('city')['Adjust_CLTV'].cumsum()\n",
    "df_new2_end['run_pct'] = df_new2_end.groupby('city')['Adjust_CLTV'].apply(lambda x: (x/x.sum()).cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This conditional create the tiers\n",
    "df_new2_end['tier'] = ['A' if x <= 0.1 else\n",
    "                       'B' if x <= 0.2 else\n",
    "                       'C' if x <= 0.3 else\n",
    "                       'D' if x <= 0.4 else\n",
    "                       'E' if x <= 0.5 else\n",
    "                       'F' if x <= 0.6 else\n",
    "                       'G' if x <= 0.7 else\n",
    "                       'H' if x <= 0.8 else\n",
    "                       'I' if x <= 0.9 else\n",
    "                       'J' for x in df_new2_end.run_pct.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J    2145\n",
       "I     524\n",
       "H     351\n",
       "G     253\n",
       "F     191\n",
       "E     148\n",
       "D     114\n",
       "C      87\n",
       "B      60\n",
       "A      33\n",
       "Name: tier, dtype: int64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new2_end.tier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2_end.rename(columns={'num_orders': 'ALL_num_orders', 'CLTV_sin_churn': 'TOTAL_CAT_CLTV_sin_churn'}, inplace=True)\n",
    "\n",
    "# df3 = df3[['city', 'customer_id', 'cat', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days', 'num_orders',\n",
    "#        'aov_cat_usd','last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order',\n",
    "#        'first_order_date', 'adjust_std', 'adjust_cohort','adjust_retention', \n",
    "#        'median_diff_days_adjusted', 'churned', 'churned_date','CLTV_sin_churn']].copy()\n",
    "\n",
    "df3.rename(columns={'num_orders': 'num_orders_cat', 'churned': 'churned_cat','CLTV_sin_churn':'CAT_CLTV_sin_churn'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'customer_id', 'min_diff_days', 'max_diff_days',\n",
       "       'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
       "       'ALL_num_orders', 'aov_ALL_usd', 'ALL_avg_cant', 'last_order_date',\n",
       "       'diff_from_last_to_first_order', 'days_since_last_order',\n",
       "       'first_order_date', 'churned_ALL', 'adjust_std', 'adjust_retention',\n",
       "       'median_diff_days_adjusted', 'cash_margin', 'TOTAL_CAT_CLTV_sin_churn',\n",
       "       'churned', 'ALL_CLTV_sin_churn', 'Adjust_CLTV', 'ALL_churned_date',\n",
       "       'business_type', 'microsegment_name', 'is_kam', 'cumsum', 'run_pct',\n",
       "       'tier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new2_end.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We merge with data_farming so we get the info farming for each customer\n",
    "df_new2_end = df_new2_end[['customer_id','ALL_num_orders', 'aov_ALL_usd', 'churned_ALL', 'ALL_churned_date','TOTAL_CAT_CLTV_sin_churn',\n",
    "       'ALL_CLTV_sin_churn', 'Adjust_CLTV','tier', 'microsegment_name', 'business_type', 'is_kam']].merge(data_farming[data_farming.ciudad == city][['customer_id','owner']], on='customer_id', how='left')\n",
    "df_new2_end[['owner']] = df_new2_end[['owner']].fillna('No Farming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2_end.rename(columns={'num_orders': 'ALL_num_orders', 'CLTV_sin_churn': 'TOTAL_CAT_CLTV_sin_churn'}, inplace=True)\n",
    "\n",
    "# df3 = df3[['city', 'customer_id', 'cat', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days', 'num_orders',\n",
    "#        'aov_cat_usd','last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order',\n",
    "#        'first_order_date', 'adjust_std', 'adjust_cohort','adjust_retention', \n",
    "#        'median_diff_days_adjusted', 'churned', 'churned_date','CLTV_sin_churn']].copy()\n",
    "\n",
    "df3.rename(columns={'num_orders': 'num_orders_cat', 'churned': 'churned_cat','CLTV_sin_churn':'CAT_CLTV_sin_churn'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df3[['city', 'customer_id', 'cat', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days', 'num_orders_cat',\n",
    "       'aov_cat_usd','last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order',\n",
    "       'first_order_date', 'adjust_std', 'adjust_cohort','adjust_retention', \n",
    "       'median_diff_days_adjusted', 'churned_cat', 'churned_date','CAT_CLTV_sin_churn']].merge(df_new2_end, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cat</th>\n",
       "      <th>min_diff_days</th>\n",
       "      <th>max_diff_days</th>\n",
       "      <th>avg_diff_days</th>\n",
       "      <th>median_diff_days</th>\n",
       "      <th>stdev_diff_days</th>\n",
       "      <th>num_orders_cat</th>\n",
       "      <th>aov_cat_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>churned_ALL</th>\n",
       "      <th>ALL_churned_date</th>\n",
       "      <th>TOTAL_CAT_CLTV_sin_churn</th>\n",
       "      <th>ALL_CLTV_sin_churn</th>\n",
       "      <th>Adjust_CLTV</th>\n",
       "      <th>tier</th>\n",
       "      <th>microsegment_name</th>\n",
       "      <th>business_type</th>\n",
       "      <th>is_kam</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VCP</td>\n",
       "      <td>54609840</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.694730</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>174.899213</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>H</td>\n",
       "      <td>Grill/Churrascaria/Espetinho</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VCP</td>\n",
       "      <td>54609840</td>\n",
       "      <td>Frutas e Verduras</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.286167</td>\n",
       "      <td>19</td>\n",
       "      <td>18.958205</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>174.899213</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>H</td>\n",
       "      <td>Grill/Churrascaria/Espetinho</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VCP</td>\n",
       "      <td>54609840</td>\n",
       "      <td>Laticínios e Ovos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.437500</td>\n",
       "      <td>10.5</td>\n",
       "      <td>11.033094</td>\n",
       "      <td>17</td>\n",
       "      <td>28.226991</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>174.899213</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>H</td>\n",
       "      <td>Grill/Churrascaria/Espetinho</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCP</td>\n",
       "      <td>54609840</td>\n",
       "      <td>Limpeza e Higiene</td>\n",
       "      <td>11.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.789609</td>\n",
       "      <td>4</td>\n",
       "      <td>6.606835</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>174.899213</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>H</td>\n",
       "      <td>Grill/Churrascaria/Espetinho</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VCP</td>\n",
       "      <td>54609840</td>\n",
       "      <td>Mercearia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.483871</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.249645</td>\n",
       "      <td>32</td>\n",
       "      <td>44.171306</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>174.899213</td>\n",
       "      <td>143.719302</td>\n",
       "      <td>H</td>\n",
       "      <td>Grill/Churrascaria/Espetinho</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VCP</td>\n",
       "      <td>135201529</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.562100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>521.300043</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VCP</td>\n",
       "      <td>135201529</td>\n",
       "      <td>Frutas e Verduras</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.820755</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.460793</td>\n",
       "      <td>107</td>\n",
       "      <td>25.655630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>521.300043</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VCP</td>\n",
       "      <td>135201529</td>\n",
       "      <td>Laticínios e Ovos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>39.908467</td>\n",
       "      <td>16</td>\n",
       "      <td>19.593204</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>521.300043</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VCP</td>\n",
       "      <td>135201529</td>\n",
       "      <td>Limpeza e Higiene</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15.363636</td>\n",
       "      <td>10.5</td>\n",
       "      <td>17.431623</td>\n",
       "      <td>23</td>\n",
       "      <td>6.542877</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>521.300043</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VCP</td>\n",
       "      <td>135201529</td>\n",
       "      <td>Mercearia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.867647</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.437486</td>\n",
       "      <td>69</td>\n",
       "      <td>29.332868</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>521.300043</td>\n",
       "      <td>460.153569</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  customer_id                cat  min_diff_days  max_diff_days  \\\n",
       "0  VCP     54609840       Descartáveis            NaN            NaN   \n",
       "1  VCP     54609840  Frutas e Verduras            1.0           28.0   \n",
       "2  VCP     54609840  Laticínios e Ovos            1.0           35.0   \n",
       "3  VCP     54609840  Limpeza e Higiene           11.0           71.0   \n",
       "4  VCP     54609840          Mercearia            1.0           28.0   \n",
       "5  VCP    135201529       Descartáveis           20.0           20.0   \n",
       "6  VCP    135201529  Frutas e Verduras            1.0           22.0   \n",
       "7  VCP    135201529  Laticínios e Ovos            1.0          153.0   \n",
       "8  VCP    135201529  Limpeza e Higiene            2.0           84.0   \n",
       "9  VCP    135201529          Mercearia            1.0           44.0   \n",
       "\n",
       "   avg_diff_days  median_diff_days  stdev_diff_days  num_orders_cat  \\\n",
       "0       0.000000               NaN         0.000000               1   \n",
       "1      12.833333              14.0         7.286167              19   \n",
       "2      14.437500              10.5        11.033094              17   \n",
       "3      37.000000              29.0        30.789609               4   \n",
       "4       7.483871               7.0         6.249645              32   \n",
       "5      20.000000              20.0         0.000000               2   \n",
       "6       3.820755               3.0         3.460793             107   \n",
       "7      26.600000               8.0        39.908467              16   \n",
       "8      15.363636              10.5        17.431623              23   \n",
       "9       5.867647               2.5         8.437486              69   \n",
       "\n",
       "   aov_cat_usd  ... churned_ALL  ALL_churned_date  TOTAL_CAT_CLTV_sin_churn  \\\n",
       "0    14.694730  ...           1        2023-01-30                143.719302   \n",
       "1    18.958205  ...           1        2023-01-30                143.719302   \n",
       "2    28.226991  ...           1        2023-01-30                143.719302   \n",
       "3     6.606835  ...           1        2023-01-30                143.719302   \n",
       "4    44.171306  ...           1        2023-01-30                143.719302   \n",
       "5     7.562100  ...           0        2023-07-06                460.153569   \n",
       "6    25.655630  ...           0        2023-07-06                460.153569   \n",
       "7    19.593204  ...           0        2023-07-06                460.153569   \n",
       "8     6.542877  ...           0        2023-07-06                460.153569   \n",
       "9    29.332868  ...           0        2023-07-06                460.153569   \n",
       "\n",
       "  ALL_CLTV_sin_churn  Adjust_CLTV  tier             microsegment_name  \\\n",
       "0         174.899213   143.719302     H  Grill/Churrascaria/Espetinho   \n",
       "1         174.899213   143.719302     H  Grill/Churrascaria/Espetinho   \n",
       "2         174.899213   143.719302     H  Grill/Churrascaria/Espetinho   \n",
       "3         174.899213   143.719302     H  Grill/Churrascaria/Espetinho   \n",
       "4         174.899213   143.719302     H  Grill/Churrascaria/Espetinho   \n",
       "5         521.300043   460.153569     D              Pratos/Refeições   \n",
       "6         521.300043   460.153569     D              Pratos/Refeições   \n",
       "7         521.300043   460.153569     D              Pratos/Refeições   \n",
       "8         521.300043   460.153569     D              Pratos/Refeições   \n",
       "9         521.300043   460.153569     D              Pratos/Refeições   \n",
       "\n",
       "   business_type  is_kam       owner  \n",
       "0    Restaurante   False  No Farming  \n",
       "1    Restaurante   False  No Farming  \n",
       "2    Restaurante   False  No Farming  \n",
       "3    Restaurante   False  No Farming  \n",
       "4    Restaurante   False  No Farming  \n",
       "5    Restaurante   False  No Farming  \n",
       "6    Restaurante   False  No Farming  \n",
       "7    Restaurante   False  No Farming  \n",
       "8    Restaurante   False  No Farming  \n",
       "9    Restaurante   False  No Farming  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_excel(f\"CLTV_{city}.xlsx\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info for SAC team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SAC = df_final[['city','customer_id','tier','Adjust_CLTV']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_to_number = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10}\n",
    "df_SAC['tier'] = df_SAC['tier'].map(letter_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SAC.to_csv(f\"{city}_SAC_tiers.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "624741679a3ae5d99cecf49b8df5d516a7a937e6e7328e129d1fa121c8592e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
