{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//----------------------------\n",
    "#//LIBRARIES\n",
    "    #Math\n",
    "import math\n",
    "    #Numeric Python\n",
    "import numpy as np\n",
    "    #Pandas (dataframes)\n",
    "import pandas as pd\n",
    "    #datetime for fate manipulation\n",
    "from datetime import date, datetime, timedelta  \n",
    "    #Regex for advanced string matching\n",
    "import re\n",
    "    #for time related stuff\n",
    "import time\n",
    "    #json library\n",
    "import json\n",
    "    #Analyst tools\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser('~'))\n",
    "from analysts_tools.growth import *\n",
    "    #Procurement tools\n",
    "from procurement_lib import send_slack_notification\n",
    "from procurement_lib import redash\n",
    "from analysts_tools.redash_methods import *\n",
    "from analystcommunity.read_connection_data_warehouse import run_read_dwd_query\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargue de Queries y parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "city = 'SPO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_date_desde = (datetime.datetime.today() - datetime.timedelta(days=200))#.strftime('%Y-%m-%d') #1 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-felipe.guevara/Growth/CLTV\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "margenes = pd.read_csv(\"/home/jupyter-felipe.guevara/Growth/CLTV/Margenes_neto.csv\")\n",
    "retention = pd.read_csv(\"/home/jupyter-felipe.guevara/Growth/CLTV/retention_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_aux =  retention.copy()\n",
    "\n",
    "for i,ret in enumerate(retention_aux.values):\n",
    "    retention_aux.iloc[i,2:] = [(1-(j-ret[-1])/100) if j-ret[-1] >= 0 else 1 for j in ret[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "clear_buyers = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",138674,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "buyers_11 = get_fresh_query_result(\"https://internal-redash.federate.frubana.com/\",212712,'SeoGHWmDUaaBi7VXje1s9zYNiMD1VHQ1K1DYOxiF',{},20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "\n",
    "c.assignee_ref_id AS \"Owner\",\n",
    "cm.member_ref_id AS \"customer_id\",\n",
    "--cm.status AS \"Estado de la asignacion\",\n",
    "--c.type as \"Tipo de asociacion\",\n",
    "--c.flow_type AS \"Tipo de carga\",\n",
    "z.value AS \"Ciudad\"\n",
    "--p.since AS \"Semana\"\n",
    "\n",
    "FROM postgres_growth_offline.\"growth_clustering.clusters\"               c\n",
    "INNER JOIN postgres_growth_offline.\"growth_clustering.cluster_members\"  cm  ON cm.cluster_id = c.id\n",
    "INNER JOIN postgres_growth_offline.\"growth_clustering.periods\"          p   ON p.id = c.period_id\n",
    "INNER JOIN postgres_growth_offline.\"growth_clustering.zones\"            z   ON z.id = c.zone_id\n",
    "\n",
    "where p.since = DATE_TRUNC('week', date(getdate()) - interval '0 week')\n",
    "and z.value in ('BOG','BAQ','MDE','CMX','SPO','BHZ','CWB','VCP')\n",
    "and c.type = 'FARMER_OFFLINE'\n",
    "and c.status = 'ACTIVE'\n",
    "and c.enabled = 'true'\n",
    "\"\"\"\n",
    "data_farming = read_connection_data_warehouse.runQuery(query)\n",
    "data_farming[[\"customer_id\"]] = data_farming[[\"customer_id\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to run the query\n",
    "def run_query_with_retry(query):\n",
    "    max_retries = 5\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Attempt to execute the query\n",
    "            data_ventas_aux = run_read_dwd_query(query)\n",
    "            data_ventas_aux[[\"gmv_usd\", \"cant\"]] = data_ventas_aux[[\"gmv_usd\", \"cant\"]].astype(float)\n",
    "            data_ventas_aux['submit_date'] = pd.to_datetime(data_ventas_aux['submit_date'])\n",
    "            return data_ventas_aux  # If successful, return the result\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            print(f\"Retrying... ({retries}/{max_retries})\")\n",
    "    # If max retries reached without success, raise an error\n",
    "    raise RuntimeError(\"Failed to execute the query after multiple retries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    s.identifier_value AS city,\n",
    "    dc.source_id AS customer_id,\n",
    "    DATE(fs.order_submitted_date) AS submit_date,\n",
    "    fs.order_id,\n",
    "    dp.card_id AS padre_sku_id,\n",
    "    cat.parent_description AS cat,\n",
    "    CASE\n",
    "        WHEN s.identifier_value = 'CMX' THEN fs.gmv_pxq_local/19.65\n",
    "        WHEN s.identifier_value IN ('SPO','BHZ','CWB','VCP') THEN fs.gmv_pxq_local/4.75\n",
    "        WHEN s.identifier_value IN ('BOG','BAQ','MDE') THEN fs.gmv_pxq_local/3776\n",
    "    ELSE fs.gmv_pxq_local \n",
    "    END AS gmv_usd,\n",
    "    fs.product_quantity_x_step_unit AS cant\n",
    "\n",
    "FROM dpr_sales.fact_sales                   fs\n",
    "INNER JOIN dpr_shared.dim_customer          dc  ON dc.customer_id = fs.dim_customer\n",
    "INNER JOIN dpr_shared.dim_site              s   ON s.site_id = fs.dim_site\n",
    "INNER JOIN dpr_shared.dim_product           dp  ON dp.product_id = fs.dim_product\n",
    "INNER JOIN dpr_shared.dim_category          cat ON cat.category_id = dp.category_id\n",
    "\n",
    "WHERE \n",
    "    fs.gmv_enabled = TRUE\n",
    "    AND fulfillment_order_status NOT IN ('CANCELLED', 'ARCHIVED','No value')\n",
    "    AND fs.fb_order_status_id  IN (1,6,7,8)\n",
    "    AND fs.is_deleted = FALSE\n",
    "    AND fs.dim_status = 1\n",
    "    AND dp.is_slot = 'false'\n",
    "    AND DATE(fs.order_submitted_date) > current_date - 730\n",
    "    AND s.identifier_value = '{city}'\n",
    "    AND dc.source_id IN {clientes}\n",
    "\"\"\".format(clientes=tuple(set(clear_buyers[clear_buyers.registered_city == city].customer_id.unique())), city = city)\n",
    "\n",
    "# Call the function with your query\n",
    "data_ventas_aux = run_query_with_retry(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Frutas e verduras', 'Frutas e Verduras')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Laticínios e ovos', 'Laticínios e Ovos')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Limpeza e higiene', 'Limpeza e Higiene')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Carnes, aves e peixes', 'Carnes, Aves e Peixes')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Abarrotes & despensa', 'Abarrotes')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Aseo e higiene', 'Aseo e Higiene')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Frutas & verduras', 'Frutas & Verduras')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Carne, pollo & pescados', 'Carne, Pollo & Pescados')\n",
    "data_ventas_aux['cat'] = data_ventas_aux['cat'].replace('Lácteos & huevos', 'Lácteos & Huevos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = data_ventas_aux.groupby(by=['customer_id']).agg({'submit_date':np.max}).reset_index()\n",
    "df = data_ventas_aux[data_ventas_aux.customer_id.isin(check_df[check_df.submit_date >= customer_date_desde].customer_id.unique())].groupby(by=['city', 'customer_id', 'submit_date','cat']).agg({'gmv_usd':'sum','cant':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacion de df con info by cat by client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('submit_date',ignore_index=True)\n",
    "\n",
    "#fix for id problems and taking into account only dates\n",
    "df['order_id']= df.submit_date.apply(lambda x:x.toordinal()) \n",
    "\n",
    "#Days of difference between orders for customer and for cat\n",
    "df['days_bet'] = (df.submit_date -df.groupby('customer_id').submit_date.transform('min')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This calculate in res the difference between consecutive orders and with the agg we calculate all metrics\n",
    "df['res'] = df.groupby(by=['customer_id', 'cat'])['days_bet'].diff()\n",
    "df_grouped = df.groupby(by=['city', 'customer_id', 'cat']).agg({'res': [np.min, np.max, np.mean, np.median, np.std],\n",
    "                                                                    'order_id': [lambda x: x.nunique()], \n",
    "                                                                    'gmv_usd': [np.mean],\n",
    "                                                                    'cant': [np.mean],\n",
    "                                                                    'submit_date': [np.max, lambda x: (x.max()-x.min()).days, lambda x: (datetime.datetime.today() - x.max()).days, np.min]\n",
    "                                                                    }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we define everything in a df2 for further processing\n",
    "df2 = df_grouped.copy()\n",
    "\n",
    "df2.columns = ['city', 'customer_id', 'cat', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
    "               'num_orders', 'aov_cat_usd', 'avg_cant_cat', 'last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order','first_order_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_month(d1, d2):\n",
    "    return (d1.year - d2.year) * 12 + d1.month - d2.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_metrics_2(cat):\n",
    "    df_cat = df2[df2.cat == cat].copy()\n",
    "    \n",
    "    df_cat['adjust_std'] = pd.qcut(df_cat.stdev_diff_days, 10, labels=[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])\n",
    "    df_cat[[\"adjust_std\"]] = df_cat[[\"adjust_std\"]].astype(float)\n",
    "    \n",
    "    df_cat['adjust_cohort'] = [1 if ((x[13]) - (x[5]+x[7]) <= 0) else  \n",
    "                 1/(((x[13]) - x[5])/x[7]) if x[7] != 0 else\n",
    "                 1/(((x[13]) - x[5])/np.round(1+(x[5]*0.7)))\n",
    "                 for x in df_cat.values]\n",
    "    \n",
    "    df_cat[\"margen\"] = [margenes[(margenes.category == x[2]) & (margenes.region_code == x[0])][\"net_margin\"].unique()[0]/100 for x in df_cat.values]\n",
    "    #mirar aca\n",
    "    df_cat['adjust_retention'] = [1 if diff_month(x[11],x[14])+1 >= 10 else \n",
    "                                  retention_aux[(retention_aux.category == x[2]) & (retention_aux.region_code == x[0])][str(diff_month(x[11],x[14])+1)].unique()[0] for x in df_cat.values]\n",
    "    \n",
    "    df_cat['median_diff_days_adjusted'] = 365/df_cat.median_diff_days\n",
    "    \n",
    "    df_cat[\"churned\"] = [0 if ((x[13]) - (x[5]+x[7]*2) <= 0) else 1 for x in df_cat.values]\n",
    "    \n",
    "    df_cat[['avg_diff_days','stdev_diff_days']] = df_cat[['avg_diff_days','stdev_diff_days']].fillna(0)\n",
    "\n",
    "    df_cat['churned_date'] = [(x[11] + datetime.timedelta(days=int(x[5]+x[7]*2))).strftime('%Y-%m-%d') for x in df_cat.values] #1 months\n",
    "    \n",
    "    df_cat[\"CLTV\"] = df_cat.median_diff_days_adjusted * df_cat.margen * df_cat.aov_cat_usd * df_cat.adjust_retention * df_cat.adjust_std * df_cat.adjust_cohort\n",
    "    df_cat[\"CLTV_sin_margen\"] = df_cat.median_diff_days_adjusted * df_cat.aov_cat_usd * df_cat.adjust_retention * df_cat.adjust_std * df_cat.adjust_cohort\n",
    "    df_cat[\"CLTV_sin_churn\"] = df_cat.median_diff_days_adjusted * df_cat.margen * df_cat.aov_cat_usd * df_cat.adjust_retention * df_cat.adjust_std\n",
    "    \n",
    "    df_cat['cash_margin'] = df_cat.aov_cat_usd * df_cat.margen\n",
    "\n",
    "    return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bebidas\n",
      "Done Bebidas\n",
      "Carnes, Aves e Peixes\n",
      "Done Carnes, Aves e Peixes\n",
      "Descartáveis\n",
      "Done Descartáveis\n",
      "Frutas e Verduras\n",
      "Done Frutas e Verduras\n",
      "Laticínios e Ovos\n",
      "Done Laticínios e Ovos\n",
      "Limpeza e Higiene\n",
      "Done Limpeza e Higiene\n",
      "Mercearia\n",
      "Done Mercearia\n",
      "Congelados\n",
      "Done Congelados\n",
      "Frubana prime\n",
      "Done Frubana prime\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "\n",
    "for cat in df2.cat.unique():\n",
    "   print(cat)\n",
    "   if cat not in ('Frubana prime','¡productos nuevos!','No value','Mesa & cocina','Insumos internos cat','Despensa'):\n",
    "      df3 = df3.append(cat_metrics_2(cat))\n",
    "   print(f'Done {cat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cat</th>\n",
       "      <th>min_diff_days</th>\n",
       "      <th>max_diff_days</th>\n",
       "      <th>avg_diff_days</th>\n",
       "      <th>median_diff_days</th>\n",
       "      <th>stdev_diff_days</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>aov_cat_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>adjust_cohort</th>\n",
       "      <th>margen</th>\n",
       "      <th>adjust_retention</th>\n",
       "      <th>median_diff_days_adjusted</th>\n",
       "      <th>churned</th>\n",
       "      <th>churned_date</th>\n",
       "      <th>CLTV</th>\n",
       "      <th>CLTV_sin_margen</th>\n",
       "      <th>CLTV_sin_churn</th>\n",
       "      <th>cash_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Bebidas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.212766</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.793221</td>\n",
       "      <td>48</td>\n",
       "      <td>40.518026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>719.735206</td>\n",
       "      <td>4929.693190</td>\n",
       "      <td>719.735206</td>\n",
       "      <td>5.915632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19355299</td>\n",
       "      <td>Bebidas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.260870</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.928843</td>\n",
       "      <td>24</td>\n",
       "      <td>20.663158</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>18.352328</td>\n",
       "      <td>125.700876</td>\n",
       "      <td>18.352328</td>\n",
       "      <td>3.016821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19360755</td>\n",
       "      <td>Bebidas</td>\n",
       "      <td>20.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>158.750000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>192.692112</td>\n",
       "      <td>5</td>\n",
       "      <td>58.272000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.195402</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-15</td>\n",
       "      <td>3.569327</td>\n",
       "      <td>24.447448</td>\n",
       "      <td>3.569327</td>\n",
       "      <td>8.507712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19565513</td>\n",
       "      <td>Bebidas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>7.759036</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.681454</td>\n",
       "      <td>84</td>\n",
       "      <td>22.067218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-16</td>\n",
       "      <td>164.634686</td>\n",
       "      <td>1127.634835</td>\n",
       "      <td>164.634686</td>\n",
       "      <td>3.221814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19567777</td>\n",
       "      <td>Bebidas</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.530120</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.935834</td>\n",
       "      <td>84</td>\n",
       "      <td>15.447619</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>123.480542</td>\n",
       "      <td>845.757138</td>\n",
       "      <td>123.480542</td>\n",
       "      <td>2.255352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  customer_id      cat  min_diff_days  max_diff_days  avg_diff_days  \\\n",
       "0   SPO     19337183  Bebidas            1.0           16.0       4.212766   \n",
       "7   SPO     19355299  Bebidas            1.0          196.0      30.260870   \n",
       "15  SPO     19360755  Bebidas           20.0          441.0     158.750000   \n",
       "21  SPO     19565513  Bebidas            1.0          108.0       7.759036   \n",
       "30  SPO     19567777  Bebidas            2.0           44.0       8.530120   \n",
       "\n",
       "    median_diff_days  stdev_diff_days  num_orders  aov_cat_usd  ...  \\\n",
       "0                3.0         3.793221          48    40.518026  ...   \n",
       "7               12.0        50.928843          24    20.663158  ...   \n",
       "15              87.0       192.692112           5    58.272000  ...   \n",
       "21               5.0        12.681454          84    22.067218  ...   \n",
       "30               6.0         6.935834          84    15.447619  ...   \n",
       "\n",
       "    adjust_cohort margen  adjust_retention  median_diff_days_adjusted churned  \\\n",
       "0             1.0  0.146               1.0                 121.666667       0   \n",
       "7             1.0  0.146               1.0                  30.416667       0   \n",
       "15            1.0  0.146               1.0                   4.195402       0   \n",
       "21            1.0  0.146               1.0                  73.000000       0   \n",
       "30            1.0  0.146               1.0                  60.833333       0   \n",
       "\n",
       "    churned_date        CLTV  CLTV_sin_margen  CLTV_sin_churn  cash_margin  \n",
       "0     2024-05-21  719.735206      4929.693190      719.735206     5.915632  \n",
       "7     2024-08-28   18.352328       125.700876       18.352328     3.016821  \n",
       "15    2025-09-15    3.569327        24.447448        3.569327     8.507712  \n",
       "21    2024-06-16  164.634686      1127.634835      164.634686     3.221814  \n",
       "30    2024-06-01  123.480542       845.757138      123.480542     2.255352  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aca empieza el analisis global by customer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, i group the df3 (the df with the whole info by cat to customer lvl)\n",
    "df_new3 = df3[['city','customer_id','aov_cat_usd','cash_margin','CLTV_sin_churn','churned']].groupby(by=['city','customer_id']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The processing data for customer level is made here\n",
    "\n",
    "df_new = df.groupby(by=['city','customer_id','order_id','submit_date']).sum().reset_index()\n",
    "\n",
    "df_new['days_bet'] = (df_new.submit_date -df_new.groupby('customer_id').submit_date.transform('min')).dt.days\n",
    "\n",
    "#This calculate in res the difference between consecutive orders and with the agg we calculate all metrics\n",
    "df_new['res'] = df_new.groupby(by=['customer_id'])['days_bet'].diff()\n",
    "df_grouped_2 = df_new.groupby(by=['city', 'customer_id']).agg({'res': [np.min, np.max, np.mean, np.median, np.std],\n",
    "                                                                    'order_id': [lambda x: x.nunique()], \n",
    "                                                                    'gmv_usd': [np.mean],\n",
    "                                                                    'cant': [np.mean],\n",
    "                                                                    'submit_date': [np.max, lambda x: (x.max()-x.min()).days, lambda x: (datetime.datetime.today() - x.max()).days, np.min]\n",
    "                                                                    }).droplevel(0, axis=\"columns\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we define everything in a df_new2 at level customer for further processing\n",
    "df_new2 = df_grouped_2.copy()\n",
    "\n",
    "df_new2.columns = ['city', 'customer_id', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
    "               'num_orders', 'aov_ALL_usd', 'ALL_avg_cant', 'last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order','first_order_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we calculate the next parameters and also integred with df_new3 where we can have the info grouped by customer about the category performance\n",
    "df_new2[\"churned_ALL\"] = [0 if ((x[12]) - (x[4]+x[6]*2) <= 0) else 1 for x in df_new2.values]\n",
    "\n",
    "df_new2['adjust_std'] = pd.qcut(df_new2.stdev_diff_days, 10, labels=[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])\n",
    "df_new2[[\"adjust_std\"]] = df_new2[[\"adjust_std\"]].astype(float)\n",
    "\n",
    "df_new2['adjust_retention'] = [1 if diff_month(x[10],x[13])+1 >= 10 else \n",
    "                                retention_aux[(retention_aux.region_code == x[0])][str(diff_month(x[10],x[13])+1)].max() for x in df_new2.values]\n",
    "\n",
    "df_new2['median_diff_days_adjusted'] = 365/df_new2.median_diff_days\n",
    "\n",
    "#this merge is to include the info for the total cash_margin, how many cats is churned and the total cat CLTV\n",
    "df_new2 = df_new2.merge(df_new3[['customer_id','cash_margin','CLTV_sin_churn','churned']], on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27648631.805063676 27404957.143180598\n"
     ]
    }
   ],
   "source": [
    "#We calculate now the CLTV taking into account the global behavior of the customer\n",
    "df_new2[\"ALL_CLTV_sin_churn\"] = df_new2.median_diff_days_adjusted * df_new2.adjust_retention * df_new2.adjust_std * df_new2.cash_margin / 2\n",
    "df_new2[['CLTV_sin_churn','ALL_CLTV_sin_churn']] = df_new2[['CLTV_sin_churn','ALL_CLTV_sin_churn']].fillna(0)\n",
    "\n",
    "#df_new2[\"CLTV\"] = df_new2.median_diff_days_adjusted * df_new2.margen * df_new2.aov_cat_usd * df_new2.adjust_retention * df_new2.adjust_std * df_new2.adjust_cohort\n",
    "#df_new2[\"CLTV_sin_margen\"] = df_new2.median_diff_days_adjusted * df_new2.aov_cat_usd * df_new2.adjust_retention * df_new2.adjust_std * df_new2.adjust_cohort\n",
    "\n",
    "#If the Total Cat CLTV is NA because it is so few orders for each category, we create a Adjust_CLTV to include the global or ALL_CLTV_sin_churn instead of the NULL value\n",
    "df_new2['Adjust_CLTV'] = [x[21] if x[19] == 0 else x[19] for x in df_new2.values]\n",
    "\n",
    "print(df_new2.Adjust_CLTV.sum(),df_new2.CLTV_sin_churn.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we calculate the ALL_churned_date based on the general behavior of the customer\n",
    "df_new2[['avg_diff_days','stdev_diff_days']] = df_new2[['avg_diff_days','stdev_diff_days']].fillna(0)\n",
    "df_new2['ALL_churned_date'] = [(x[10] + datetime.timedelta(days=int(x[4]+x[6]*2))).strftime('%Y-%m-%d') for x in df_new2.values] #1 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final processing of the file to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will merge the df_new2 with the clear_buyers in order to filter by restaurants and take away kams (also to include the microsegment)\n",
    "df_new2 = df_new2.merge(clear_buyers[clear_buyers.registered_city == city][['customer_id','business_type','microsegment_name','is_kam']], on='customer_id', how='left')\n",
    "df_new2_end = df_new2[(df_new2.is_kam == 0)].copy() #df_new2[(df_new2.business_type == 'Restaurante') & (df_new2.is_kam == 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is to calculate the cumulative sum to create the tiers further\n",
    "df_new2_end = df_new2_end.sort_values(['Adjust_CLTV'], ascending=[False])\n",
    "df_new2_end['cumsum'] = df_new2_end.groupby('city')['Adjust_CLTV'].cumsum()\n",
    "df_new2_end['run_pct'] = df_new2_end.groupby('city')['Adjust_CLTV'].apply(lambda x: (x/x.sum()).cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This conditional create the tiers\n",
    "df_new2_end['tier'] = ['A' if x <= 0.1 else\n",
    "                       'B' if x <= 0.2 else\n",
    "                       'C' if x <= 0.3 else\n",
    "                       'D' if x <= 0.4 else\n",
    "                       'E' if x <= 0.5 else\n",
    "                       'F' if x <= 0.6 else\n",
    "                       'G' if x <= 0.7 else\n",
    "                       'H' if x <= 0.8 else\n",
    "                       'I' if x <= 0.9 else\n",
    "                       'J' for x in df_new2_end.run_pct.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J    16324\n",
       "I     3968\n",
       "H     2464\n",
       "G     1736\n",
       "F     1314\n",
       "E     1014\n",
       "D      789\n",
       "C      591\n",
       "B      421\n",
       "A      173\n",
       "Name: tier, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new2_end.tier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2_end.rename(columns={'num_orders': 'ALL_num_orders', 'CLTV_sin_churn': 'TOTAL_CAT_CLTV_sin_churn'}, inplace=True)\n",
    "\n",
    "df3.rename(columns={'num_orders': 'num_orders_cat', 'churned': 'churned_cat','CLTV_sin_churn':'CAT_CLTV_sin_churn'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'customer_id', 'min_diff_days', 'max_diff_days',\n",
       "       'avg_diff_days', 'median_diff_days', 'stdev_diff_days',\n",
       "       'ALL_num_orders', 'aov_ALL_usd', 'ALL_avg_cant', 'last_order_date',\n",
       "       'diff_from_last_to_first_order', 'days_since_last_order',\n",
       "       'first_order_date', 'churned_ALL', 'adjust_std', 'adjust_retention',\n",
       "       'median_diff_days_adjusted', 'cash_margin', 'TOTAL_CAT_CLTV_sin_churn',\n",
       "       'churned', 'ALL_CLTV_sin_churn', 'Adjust_CLTV', 'ALL_churned_date',\n",
       "       'business_type', 'microsegment_name', 'is_kam', 'cumsum', 'run_pct',\n",
       "       'tier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new2_end.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We merge with data_farming so we get the info farming for each customer\n",
    "df_new2_end = df_new2_end[['customer_id','ALL_num_orders', 'aov_ALL_usd', 'churned_ALL', 'ALL_churned_date','TOTAL_CAT_CLTV_sin_churn',\n",
    "       'ALL_CLTV_sin_churn', 'Adjust_CLTV','tier', 'microsegment_name', 'business_type', 'is_kam']].merge(data_farming[data_farming.ciudad == city][['customer_id','owner']], on='customer_id', how='left')\n",
    "df_new2_end[['owner']] = df_new2_end[['owner']].fillna('No Farming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2_end.rename(columns={'num_orders': 'ALL_num_orders', 'CLTV_sin_churn': 'TOTAL_CAT_CLTV_sin_churn'}, inplace=True)\n",
    "\n",
    "df3.rename(columns={'num_orders': 'num_orders_cat', 'churned': 'churned_cat','CLTV_sin_churn':'CAT_CLTV_sin_churn'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df3[['city', 'customer_id', 'cat', 'min_diff_days', 'max_diff_days', 'avg_diff_days', 'median_diff_days', 'stdev_diff_days', 'num_orders_cat',\n",
    "       'aov_cat_usd','last_order_date', 'diff_from_last_to_first_order', 'days_since_last_order',\n",
    "       'first_order_date', 'adjust_std', 'adjust_cohort','adjust_retention', \n",
    "       'median_diff_days_adjusted', 'churned_cat', 'churned_date','CAT_CLTV_sin_churn']].merge(df_new2_end, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cat</th>\n",
       "      <th>min_diff_days</th>\n",
       "      <th>max_diff_days</th>\n",
       "      <th>avg_diff_days</th>\n",
       "      <th>median_diff_days</th>\n",
       "      <th>stdev_diff_days</th>\n",
       "      <th>num_orders_cat</th>\n",
       "      <th>aov_cat_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>churned_ALL</th>\n",
       "      <th>ALL_churned_date</th>\n",
       "      <th>TOTAL_CAT_CLTV_sin_churn</th>\n",
       "      <th>ALL_CLTV_sin_churn</th>\n",
       "      <th>Adjust_CLTV</th>\n",
       "      <th>tier</th>\n",
       "      <th>microsegment_name</th>\n",
       "      <th>business_type</th>\n",
       "      <th>is_kam</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Bebidas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.212766</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.793221</td>\n",
       "      <td>48</td>\n",
       "      <td>40.518026</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>2342.033252</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>D</td>\n",
       "      <td>Lanches</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Carnes, Aves e Peixes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.387127</td>\n",
       "      <td>5</td>\n",
       "      <td>39.293533</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>2342.033252</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>D</td>\n",
       "      <td>Lanches</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.477896</td>\n",
       "      <td>6</td>\n",
       "      <td>3.219298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>2342.033252</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>D</td>\n",
       "      <td>Lanches</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Frutas e Verduras</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.605263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.487724</td>\n",
       "      <td>77</td>\n",
       "      <td>16.900697</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>2342.033252</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>D</td>\n",
       "      <td>Lanches</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Laticínios e Ovos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>15.727273</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.106086</td>\n",
       "      <td>12</td>\n",
       "      <td>14.409123</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>2342.033252</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>D</td>\n",
       "      <td>Lanches</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Limpeza e Higiene</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.444444</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.678379</td>\n",
       "      <td>10</td>\n",
       "      <td>8.660210</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>2342.033252</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>D</td>\n",
       "      <td>Lanches</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19337183</td>\n",
       "      <td>Mercearia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.104167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.969241</td>\n",
       "      <td>49</td>\n",
       "      <td>37.626208</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>2342.033252</td>\n",
       "      <td>2495.073655</td>\n",
       "      <td>D</td>\n",
       "      <td>Lanches</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>No Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19355299</td>\n",
       "      <td>Bebidas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.260870</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.928843</td>\n",
       "      <td>24</td>\n",
       "      <td>20.663158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>2748.027133</td>\n",
       "      <td>1608.688138</td>\n",
       "      <td>2748.027133</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>thiago.abreu@frubana.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19355299</td>\n",
       "      <td>Carnes, Aves e Peixes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.821429</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.993782</td>\n",
       "      <td>57</td>\n",
       "      <td>30.696004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>2748.027133</td>\n",
       "      <td>1608.688138</td>\n",
       "      <td>2748.027133</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>thiago.abreu@frubana.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SPO</td>\n",
       "      <td>19355299</td>\n",
       "      <td>Descartáveis</td>\n",
       "      <td>148.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>158.500000</td>\n",
       "      <td>158.5</td>\n",
       "      <td>14.849242</td>\n",
       "      <td>3</td>\n",
       "      <td>1.924912</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>2748.027133</td>\n",
       "      <td>1608.688138</td>\n",
       "      <td>2748.027133</td>\n",
       "      <td>D</td>\n",
       "      <td>Pratos/Refeições</td>\n",
       "      <td>Restaurante</td>\n",
       "      <td>False</td>\n",
       "      <td>thiago.abreu@frubana.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  customer_id                    cat  min_diff_days  max_diff_days  \\\n",
       "0  SPO     19337183                Bebidas            1.0           16.0   \n",
       "1  SPO     19337183  Carnes, Aves e Peixes            7.0           33.0   \n",
       "2  SPO     19337183           Descartáveis            6.0           55.0   \n",
       "3  SPO     19337183      Frutas e Verduras            1.0           16.0   \n",
       "4  SPO     19337183      Laticínios e Ovos            1.0           53.0   \n",
       "5  SPO     19337183      Limpeza e Higiene            2.0           36.0   \n",
       "6  SPO     19337183              Mercearia            1.0           20.0   \n",
       "7  SPO     19355299                Bebidas            1.0          196.0   \n",
       "8  SPO     19355299  Carnes, Aves e Peixes            1.0           44.0   \n",
       "9  SPO     19355299           Descartáveis          148.0          169.0   \n",
       "\n",
       "   avg_diff_days  median_diff_days  stdev_diff_days  num_orders_cat  \\\n",
       "0       4.212766               3.0         3.793221              48   \n",
       "1      16.500000              13.0        11.387127               5   \n",
       "2      16.600000               7.0        21.477896               6   \n",
       "3       2.605263               2.0         2.487724              77   \n",
       "4      15.727273               7.0        17.106086              12   \n",
       "5      13.444444              11.0        10.678379              10   \n",
       "6       4.104167               3.0         3.969241              49   \n",
       "7      30.260870              12.0        50.928843              24   \n",
       "8       6.821429               4.0         6.993782              57   \n",
       "9     158.500000             158.5        14.849242               3   \n",
       "\n",
       "   aov_cat_usd  ... churned_ALL  ALL_churned_date  TOTAL_CAT_CLTV_sin_churn  \\\n",
       "0    40.518026  ...           0        2024-05-15               2495.073655   \n",
       "1    39.293533  ...           0        2024-05-15               2495.073655   \n",
       "2     3.219298  ...           0        2024-05-15               2495.073655   \n",
       "3    16.900697  ...           0        2024-05-15               2495.073655   \n",
       "4    14.409123  ...           0        2024-05-15               2495.073655   \n",
       "5     8.660210  ...           0        2024-05-15               2495.073655   \n",
       "6    37.626208  ...           0        2024-05-15               2495.073655   \n",
       "7    20.663158  ...           0        2024-05-19               2748.027133   \n",
       "8    30.696004  ...           0        2024-05-19               2748.027133   \n",
       "9     1.924912  ...           0        2024-05-19               2748.027133   \n",
       "\n",
       "  ALL_CLTV_sin_churn  Adjust_CLTV  tier  microsegment_name  business_type  \\\n",
       "0        2342.033252  2495.073655     D            Lanches    Restaurante   \n",
       "1        2342.033252  2495.073655     D            Lanches    Restaurante   \n",
       "2        2342.033252  2495.073655     D            Lanches    Restaurante   \n",
       "3        2342.033252  2495.073655     D            Lanches    Restaurante   \n",
       "4        2342.033252  2495.073655     D            Lanches    Restaurante   \n",
       "5        2342.033252  2495.073655     D            Lanches    Restaurante   \n",
       "6        2342.033252  2495.073655     D            Lanches    Restaurante   \n",
       "7        1608.688138  2748.027133     D   Pratos/Refeições    Restaurante   \n",
       "8        1608.688138  2748.027133     D   Pratos/Refeições    Restaurante   \n",
       "9        1608.688138  2748.027133     D   Pratos/Refeições    Restaurante   \n",
       "\n",
       "   is_kam                     owner  \n",
       "0   False                No Farming  \n",
       "1   False                No Farming  \n",
       "2   False                No Farming  \n",
       "3   False                No Farming  \n",
       "4   False                No Farming  \n",
       "5   False                No Farming  \n",
       "6   False                No Farming  \n",
       "7   False  thiago.abreu@frubana.com  \n",
       "8   False  thiago.abreu@frubana.com  \n",
       "9   False  thiago.abreu@frubana.com  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final.to_excel(f\"CLTV_{city}.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info for SAC team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SAC = df_final[['city','customer_id','tier','Adjust_CLTV']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_to_number = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10}\n",
    "df_SAC['tier'] = df_SAC['tier'].map(letter_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the customer_ids\n",
    "for customer_id in buyers_11.loc[buyers_11.region_code == city].uid.unique():\n",
    "    # Check if customer_id is already in the DataFrame\n",
    "    if customer_id in df_SAC['customer_id'].values:\n",
    "        # If yes, change its tier to 11\n",
    "        df_SAC.loc[df_SAC['customer_id'] == customer_id, 'tier'] = 11\n",
    "    else:\n",
    "        # If not, add a new row with tier 11\n",
    "        df_SAC = df_SAC.append({'city': city, 'customer_id': customer_id, 'tier': 11, 'Adjust_CLTV':1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SAC.to_csv(f\"/home/jupyter-felipe.guevara/Growth/CLTV/{city}_SAC_tiers.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "624741679a3ae5d99cecf49b8df5d516a7a937e6e7328e129d1fa121c8592e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
